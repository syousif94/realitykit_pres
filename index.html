<!doctype html>
<html lang="en">
  <head>
    <meta charset="UTF-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>ARKit &amp; RealityKit with LiDAR — Interactive Guide</title>
    <link rel="preconnect" href="https://fonts.googleapis.com" />
    <link
      href="https://fonts.googleapis.com/css2?family=JetBrains+Mono:wght@400;500;600;700&family=Inter:wght@400;500;600;700&family=Instrument+Serif&display=swap"
      rel="stylesheet"
    />
    <style>
      *,
      *::before,
      *::after {
        margin: 0;
        padding: 0;
        box-sizing: border-box;
      }
      :root {
        --bg: #fff;
        --bg-code: #fafafa;
        --bg-panel: #f5f5f5;
        --border: #e5e5e5;
        --border-lt: #f0f0f0;
        --tx: #1a1a1a;
        --tx2: #4a4a4a;
        --txd: #717171;
        --txm: #a0a0a0;
        --ac: #0066ff;
        --ac-lt: #e8f0ff;
        --grn: #16a34a;
        --org: #ea580c;
        --pur: #7c3aed;
        --pnk: #db2777;
        --red: #dc2626;
        --cyn: #0891b2;
        --hl: rgba(0, 102, 255, 0.1);
        --sk: #7c3aed;
        --st: #0066ff;
        --sf: #b45309;
        --ss: #16a34a;
        --sc: #a0a0a0;
        --sp: #db2777;
        --sn: #ea580c;
        --se: #0891b2;
      }
      html {
        scroll-behavior: smooth;
      }
      body {
        background: var(--bg);
        color: var(--tx);
        font-family:
          'Inter',
          -apple-system,
          system-ui,
          sans-serif;
        line-height: 1.6;
        overflow-x: hidden;
        -webkit-font-smoothing: antialiased;
      }

      .hero {
        min-height: 100vh;
        display: flex;
        flex-direction: column;
        justify-content: center;
        padding: 4rem;
        position: relative;
        border-bottom: 1px solid var(--border);
      }
      .hero-label {
        font-family: 'JetBrains Mono', monospace;
        font-size: 0.7rem;
        letter-spacing: 0.15em;
        text-transform: uppercase;
        color: var(--ac);
        margin-bottom: 1.5rem;
        font-weight: 500;
      }
      .hero h1 {
        font-family:
          'SF Pro Display',
          system-ui,
          -apple-system,
          BlinkMacSystemFont,
          'Helvetica Neue',
          Helvetica,
          Arial,
          sans-serif;
        font-size: clamp(3rem, 7vw, 4rem);
        font-weight: 600;
        letter-spacing: -0.003em;
        line-height: 1.08;
        margin-bottom: 1.5rem;
        -webkit-font-smoothing: antialiased;
      }
      .hero h1 span {
        color: var(--ac);
      }
      .hero-desc {
        font-size: 1.1rem;
        color: var(--txd);
        max-width: 520px;
        line-height: 1.7;
      }
      .hero-nav {
        display: flex;
        flex-wrap: wrap;
        gap: 0.4rem;
        margin-top: 2.5rem;
      }
      .hero-nav a {
        font-size: 0.8rem;
        font-weight: 500;
        padding: 0.45rem 1rem;
        border: 1px solid var(--border);
        border-radius: 100px;
        color: var(--tx2);
        text-decoration: none;
        transition: all 0.2s;
      }
      .hero-nav a:hover {
        border-color: var(--ac);
        color: var(--ac);
        background: var(--ac-lt);
      }
      .scroll-cue {
        position: absolute;
        bottom: 2.5rem;
        left: 4rem;
        display: flex;
        align-items: center;
        gap: 0.75rem;
        color: var(--txm);
        font-size: 0.75rem;
        font-weight: 500;
      }
      .scroll-cue svg {
        animation: bob 2s ease-in-out infinite;
      }
      @keyframes bob {
        0%,
        100% {
          transform: translateY(0);
        }
        50% {
          transform: translateY(4px);
        }
      }

      .divider {
        padding: 3rem 3rem 2rem 4rem;
      }
      .divider .num {
        font-family: 'JetBrains Mono', monospace;
        font-size: 0.78rem;
        font-weight: 600;
        letter-spacing: 0.2em;
        color: var(--ac);
        margin-bottom: 0.75rem;
      }
      .divider h2 {
        font-family:
          'SF Pro Display',
          system-ui,
          -apple-system,
          BlinkMacSystemFont,
          'Helvetica Neue',
          Helvetica,
          Arial,
          sans-serif;
        font-size: clamp(1.8rem, 3.5vw, 2rem);
        font-weight: 600;
        color: rgb(29, 29, 31);
        letter-spacing: 0.004em;
        line-height: 1.25;
        margin-bottom: 0.6rem;
        -webkit-font-smoothing: antialiased;
      }
      .divider p {
        color: var(--txd);
        font-size: 1.2rem;
        line-height: 1.7;
      }

      .section {
        display: grid;
        grid-template-columns: 1fr 1fr;
        min-height: 100vh;
        border-top: 1px solid var(--border);
      }
      .code-panel {
        position: sticky;
        top: 0;
        height: 100vh;
        background: var(--bg-code);
        border-right: 1px solid var(--border);
        display: flex;
        flex-direction: column;
        order: -1;
      }
      .code-bar {
        display: flex;
        align-items: center;
        gap: 0.75rem;
        padding: 0.8rem 1.25rem;
        border-bottom: 1px solid var(--border);
        background: var(--bg);
      }
      .dots {
        display: flex;
        gap: 5px;
      }
      .dots span {
        width: 9px;
        height: 9px;
        border-radius: 50%;
      }
      .dots span:nth-child(1) {
        background: #ff5f57;
      }
      .dots span:nth-child(2) {
        background: #febc2e;
      }
      .dots span:nth-child(3) {
        background: #28c840;
      }
      .code-fname {
        font-family: 'JetBrains Mono', monospace;
        font-size: 0.84rem;
        color: var(--txm);
        font-weight: 500;
      }
      .code-scroll {
        flex: 1;
        overflow-y: auto;
        padding: 1rem 0;
      }
      .code-scroll::-webkit-scrollbar {
        width: 5px;
      }
      .code-scroll::-webkit-scrollbar-track {
        background: transparent;
      }
      .code-scroll::-webkit-scrollbar-thumb {
        background: var(--border);
        border-radius: 3px;
      }
      .cl {
        display: flex;
        padding: 0 1.25rem;
        min-height: 1.55em;
        line-height: 1.55;
        transition: background 0.25s;
        font-family: 'JetBrains Mono', monospace;
        font-size: 0.94rem;
      }
      .cl.hl {
        background: var(--hl);
      }
      .cl .ln {
        width: 2.5ch;
        text-align: right;
        color: var(--txm);
        margin-right: 1.25rem;
        user-select: none;
        flex-shrink: 0;
        font-size: 0.82rem;
        line-height: 1.8;
        opacity: 0.6;
      }
      .cl code {
        white-space: pre;
        font-family: inherit;
      }
      .kw {
        color: var(--sk);
        font-weight: 600;
      }
      .tp {
        color: var(--st);
      }
      .fn {
        color: var(--sf);
      }
      .st {
        color: var(--ss);
      }
      .cm {
        color: var(--sc);
        font-style: italic;
      }
      .pr {
        color: var(--sp);
      }
      .nm {
        color: var(--sn);
      }
      .en {
        color: var(--se);
      }
      .pm {
        color: var(--tx2);
      }

      .explain-panel {
        padding: 0;
      }
      .expl {
        padding: 3rem 3rem 3rem 4rem;
        display: flex;
        flex-direction: column;
        justify-content: center;
        min-height: 44vh;
      }
      .expl + .expl {
        border-top: 1px solid var(--border-lt);
      }
      .expl-label {
        font-size: 0.78rem;
        font-weight: 600;
        letter-spacing: 0.12em;
        text-transform: uppercase;
        color: var(--ac);
        margin-bottom: 0.6rem;
      }
      .expl h3 {
        font-family:
          'SF Pro Display',
          system-ui,
          -apple-system,
          BlinkMacSystemFont,
          'Helvetica Neue',
          Helvetica,
          Arial,
          sans-serif;
        font-size: 1.4rem;
        font-weight: 600;
        color: rgb(29, 29, 31);
        letter-spacing: 0.004em;
        margin-bottom: 0.8rem;
        line-height: 1.3;
        -webkit-font-smoothing: antialiased;
        line-height: 1.35;
      }
      .expl p {
        color: var(--tx2);
        font-size: 1.1rem;
        line-height: 1.75;
        margin-bottom: 0.6rem;
        max-width: 520px;
      }
      .tag {
        display: inline;
        font-family: 'JetBrains Mono', monospace;
        font-size: 0.94rem;
        color: var(--ac);
        white-space: nowrap;
        font-weight: 500;
      }
      .note {
        margin-top: 0.8rem;
        padding: 0.7rem 0.9rem;
        background: var(--ac-lt);
        border-left: 2.5px solid var(--ac);
        border-radius: 0 6px 6px 0;
        font-size: 1rem;
        color: var(--tx2);
        max-width: 520px;
        line-height: 1.65;
      }
      .illust {
        margin: 1rem 0 0.5rem;
        max-width: 420px;
        border-radius: 10px;
        overflow: hidden;
        border: 1px solid var(--border);
        background: var(--bg);
      }
      .illust svg {
        display: block;
        width: 100%;
        height: auto;
      }
      .illust canvas {
        display: block;
        width: 100%;
        height: auto;
        border-radius: 10px;
        background: #fafafa;
      }

      @media (max-width: 960px) {
        .section {
          grid-template-columns: 1fr;
        }
        .code-panel {
          position: relative;
          height: auto;
          max-height: 55vh;
          border-left: none;
          border-bottom: 1px solid var(--border);
          order: -1;
        }
        .expl {
          min-height: auto;
          padding: 2rem 1.5rem;
        }
        .hero {
          padding: 3rem 1.5rem;
        }
        .divider {
          padding: 3rem 1.5rem 2.5rem;
        }
      }
      footer {
        padding: 4rem;
        border-top: 1px solid var(--border);
        text-align: center;
        color: var(--txm);
        font-size: 0.8rem;
      }
    </style>
    <script type="importmap">
      {
        "imports": {
          "three": "https://cdn.jsdelivr.net/npm/three@0.163.0/build/three.module.js",
          "three/addons/": "https://cdn.jsdelivr.net/npm/three@0.163.0/examples/jsm/"
        }
      }
    </script>
  </head>
  <body>
    <section class="hero">
      <div class="hero-label">Swift · iOS 17+ · LiDAR</div>
      <h1>ARKit &amp; <span>RealityKit</span><br />with LiDAR</h1>
      <div class="hero-nav">
        <a href="#s-setup">Setup</a><a href="#s-types">Core Types</a
        ><a href="#s-anchors">Anchors</a><a href="#s-depth">Depth Buffers</a
        ><a href="#s-usdz">Models</a><a href="#s-gestures">Gestures</a
        ><a href="#s-coords">Coordinates</a><a href="#s-spawn">Spawning</a
        ><a href="#s-kinematic">Kinematic</a><a href="#s-joystick">Joystick</a
        ><a href="#s-drag">Dragging</a><a href="#s-raycasting">Raycasting</a
        ><a href="#s-hits">Hit Testing</a
        ><a href="#s-interactions">Interactions</a
        ><a href="#s-delegate">Delegate</a
        ><a href="#s-scene">Scene Understanding</a
        ><a href="#s-tap">Tap-to-Place</a><a href="#s-mesh">Mesh</a
        ><a href="#s-outline">Outlines</a><a href="#s-handpinch">Hand Pinch</a
        ><a href="#s-usdzanim">USDZ Animations</a
        ><a href="#s-meshcross">Mesh Crossing</a>
      </div>
      <div class="scroll-cue">
        <svg width="16" height="16" fill="none">
          <path
            d="M8 3v10M4 9l4 4 4-4"
            stroke="currentColor"
            stroke-width="1.5"
            stroke-linecap="round"
            stroke-linejoin="round"
          /></svg
        >Scroll to begin
      </div>
    </section>

    <!-- ====== 01 SETUP ====== -->
    <div class="section" data-section="setup">
      <div class="explain-panel">
        <div class="divider" id="s-setup">
          <div class="num">01 — SETUP</div>
          <h2>Session Setup</h2>
          <p>
            Configure AR tracking with LiDAR mesh reconstruction, plane
            detection, and real-time depth sensing.
          </p>
        </div>
        <div class="expl" data-hl="1-3">
          <div class="expl-label">Imports</div>
          <h3>Three frameworks working together</h3>
          <p>
            <span class="tag">SwiftUI</span> provides the UI layer.
            <span class="tag">RealityKit</span> renders 3D content.
            <span class="tag">ARKit</span> handles real-world tracking — camera
            pose, planes, and LiDAR.
          </p>
        </div>
        <div class="expl" data-hl="5-8">
          <div class="expl-label">Core Objects</div>
          <h3>ARView + Configuration</h3>
          <p>
            <span class="tag">ARView</span> shows the camera feed with 3D
            overlays. We wrap it in
            <span class="tag">UIViewRepresentable</span> for SwiftUI.
          </p>
          <p>
            <span class="tag">ARWorldTrackingConfiguration</span> tracks 6
            degrees of freedom (position X/Y/Z + rotation pitch/yaw/roll) using
            camera, IMU, and LiDAR.
          </p>
        </div>
        <div class="expl" data-hl="10-14">
          <div class="expl-label">LiDAR Features</div>
          <h3>Configuration properties</h3>
          <p>
            <span class="tag">sceneReconstruction</span> — type
            <span class="tag"
              >ARWorldTrackingConfiguration.SceneReconstruction</span
            >
            (OptionSet). <span class="tag">.mesh</span> builds a triangle mesh
            of the room. <span class="tag">.meshWithClassification</span> adds
            per-face labels (floor, wall, table, seat, door, window, ceiling).
          </p>
          <p>
            <span class="tag">planeDetection</span> — type
            <span class="tag">ARWorldTrackingConfiguration.PlaneDetection</span>
            (OptionSet). <span class="tag">.horizontal</span> = floors &amp;
            tables. <span class="tag">.vertical</span> = walls. Use both for
            full room mapping.
          </p>
          <p>
            <span class="tag">environmentTexturing</span> — type
            <span class="tag"
              >ARWorldTrackingConfiguration.EnvironmentTexturing</span
            >
            (enum). <span class="tag">.automatic</span> captures environment
            cube-maps so virtual objects reflect real-world lighting.
            <span class="tag">.manual</span> gives you control over when to
            probe.
          </p>
          <p>
            <span class="tag">frameSemantics</span> — type
            <span class="tag">ARConfiguration.FrameSemantics</span> (OptionSet).
            <span class="tag">.sceneDepth</span> = raw LiDAR depth
            (CVPixelBuffer, each pixel = meters).
            <span class="tag">.smoothedSceneDepth</span> = temporally filtered
            (less jitter, better for rendering). Both require a LiDAR-equipped
            device.
          </p>
        </div>
        <div class="expl" data-hl="16-17">
          <div class="expl-label">Launch</div>
          <h3>Start the AR session &amp; assign delegate</h3>
          <p>
            <span class="tag">session.run(config)</span> activates tracking.
            <span class="tag">session.delegate</span> wires up the
            <span class="tag">Coordinator</span> so it receives per-frame
            callbacks. Without this line, none of the delegate methods fire.
          </p>
        </div>
        <div class="expl" data-hl="28-37">
          <div class="expl-label">Delegate</div>
          <h3>Setting up ARView &amp; Delegate</h3>
          <p>
            A <span class="tag">Coordinator</span> class conforms to
            <span class="tag">NSObject</span> and
            <span class="tag">ARSessionDelegate</span>. SwiftUI's
            <span class="tag">makeCoordinator()</span> creates it, and we assign
            it as the session's delegate in <span class="tag">makeUIView</span>.
          </p>
          <p>
            The delegate receives per-frame updates, new anchors, and depth data
            — it's where all your AR logic lives.
          </p>
          <div class="note">
            Without setting <span class="tag">session.delegate</span>, none of
            the <span class="tag">ARSessionDelegate</span> callbacks (<span
              class="tag"
              >didUpdate frame</span
            >, <span class="tag">didAdd anchors</span>, etc.) will fire.
          </div>
        </div>
        <div class="expl" data-hl="19-24">
          <div class="expl-label">Coaching Overlay</div>
          <h3>"Move your phone around"</h3>
          <p>
            <span class="tag">ARCoachingOverlayView</span> is Apple's built-in
            tutorial view that tells users to move their phone around so ARKit
            can detect surfaces. It shows animated instructions and
            automatically hides once enough of the environment is mapped.
          </p>
          <p>
            Set <span class="tag">goal</span> to
            <span class="tag">.horizontalPlane</span> (floor/table) or
            <span class="tag">.anyPlane</span>. The overlay will display until
            ARKit has confidently detected a matching surface. For ground-plane
            apps, <span class="tag">.horizontalPlane</span> is the right choice.
          </p>
          <p>
            Call <span class="tag">activatesAutomatically = true</span> so it
            re-appears if tracking is lost. Add it as a subview of your
            <span class="tag">ARView</span> and set
            <span class="tag">session</span> so it knows which AR session to
            monitor.
          </p>
          <div class="note">
            The coaching overlay also fires
            <span class="tag">ARCoachingOverlayViewDelegate</span> callbacks
            like <span class="tag">coachingOverlayViewDidDeactivate</span>
            &mdash; useful for starting your game or placing initial content
            only after the user has successfully scanned the room.
          </div>
        </div>
      </div>
      <div class="code-panel">
        <div class="code-bar">
          <div class="dots"><span></span><span></span><span></span></div>
          <div class="code-fname">ARSetup.swift</div>
        </div>
        <div class="code-scroll" id="code-setup"></div>
      </div>
    </div>

    <!-- ====== 01b CORE TYPES ====== -->
    <div class="section" data-section="types">
      <div class="explain-panel">
        <div class="divider" id="s-types">
          <div class="num">01b — CORE TYPES</div>
          <h2>The Five Objects You Touch</h2>
          <p>
            Every AR app revolves around the same handful of types. Here’s what
            each one holds.
          </p>
        </div>
        <div class="expl" data-hl="1-9">
          <div class="expl-label">ARView</div>
          <h3>The view that renders everything</h3>
          <p>
            <span class="tag">ARView</span> is a UIView subclass that composites
            the camera feed with RealityKit’s 3D rendering. Its
            <span class="tag">.session</span> property gives you the underlying
            <span class="tag">ARSession</span>, and its
            <span class="tag">.scene</span> is the root of the entity hierarchy
            where you add anchors.
          </p>
          <p>
            It also provides convenience methods like
            <span class="tag">raycast(from:allowing:alignment:)</span> and
            <span class="tag">entity(at:)</span> for interaction.
          </p>
        </div>
        <div class="expl" data-hl="11-19">
          <div class="expl-label">ARSession</div>
          <h3>The tracking engine</h3>
          <p>
            <span class="tag">ARSession</span> manages device tracking. You call
            <span class="tag">.run(config)</span> to start it and assign a
            <span class="tag">.delegate</span> to receive callbacks. Its
            <span class="tag">.currentFrame</span> gives you the latest
            <span class="tag">ARFrame</span> at any time.
          </p>
        </div>
        <div class="expl" data-hl="21-32">
          <div class="expl-label">ARFrame</div>
          <h3>One snapshot of the world</h3>
          <p>
            Delivered ~60×/sec, each <span class="tag">ARFrame</span> bundles
            the camera image, camera pose, LiDAR depth, detected anchors, and
            lighting estimate into a single immutable object. The
            <span class="tag">.camera</span> property is an
            <span class="tag">ARCamera</span> with the device’s
            <span class="tag">.transform</span> (pose),
            <span class="tag">.intrinsics</span> (focal length), and
            <span class="tag">.projectionMatrix</span>.
          </p>
        </div>
        <div class="expl" data-hl="34-42">
          <div class="expl-label">ARAnchor</div>
          <h3>A tracked position in the real world</h3>
          <p>
            <span class="tag">ARAnchor</span> is the base class. Subclasses like
            <span class="tag">ARPlaneAnchor</span> and
            <span class="tag">ARMeshAnchor</span> add geometry data. Each anchor
            carries a <span class="tag">.transform</span>
            (simd_float4x4) that ARKit continuously refines.
          </p>
        </div>
        <div class="expl" data-hl="44-54">
          <div class="expl-label">Entity</div>
          <h3>Everything in the scene graph</h3>
          <p>
            <span class="tag">Entity</span> is the base node.
            <span class="tag">AnchorEntity</span> roots a sub-tree in the scene.
            <span class="tag">ModelEntity</span> adds a mesh and materials for
            rendering. Entities have a
            <span class="tag">.transform</span> (position, rotation, scale) and
            can have children, forming a tree.
          </p>
          <p>
            Add <span class="tag">CollisionComponent</span> for hit-testing and
            <span class="tag">PhysicsBodyComponent</span> for physics.
          </p>
        </div>
      </div>
      <div class="code-panel">
        <div class="code-bar">
          <div class="dots"><span></span><span></span><span></span></div>
          <div class="code-fname">CoreTypes.swift</div>
        </div>
        <div class="code-scroll" id="code-types"></div>
      </div>
    </div>

    <!-- ====== 02 ANCHORS (unified) ====== -->
    <div class="section" data-section="anchors">
      <div class="explain-panel">
        <div class="divider" id="s-anchors">
          <div class="num">02 — ANCHORS</div>
          <h2>AnchorEntity &amp; the Scene Graph</h2>
          <p>
            Every virtual object needs an anchor to exist in the AR scene. Here
            are all the ways to create one.
          </p>
        </div>
        <div class="expl" data-hl="1-10">
          <div class="expl-label">Ground Plane via Delegate</div>
          <h3>Getting a ground plane in the Coordinator</h3>
          <p>
            The most common need is detecting the floor. In your
            <span class="tag">Coordinator</span> (which conforms to
            <span class="tag">ARSessionDelegate</span>), implement
            <span class="tag">session(_:didAdd:)</span>. ARKit calls it
            automatically as the user moves the phone and surfaces are detected.
            Cast each anchor to <span class="tag">ARPlaneAnchor</span> and check
            <span class="tag">.classification == .floor</span> to find the
            ground plane.
          </p>
          <p>
            Wrap it in <span class="tag">AnchorEntity(anchor:)</span> to create
            a RealityKit anchor that stays synced as ARKit refines the plane.
            Build a <span class="tag">ModelEntity</span>, add it as a child, and
            call <span class="tag">scene.addAnchor()</span>.
          </p>
          <div class="note">
            The delegate fires automatically &mdash; you don’t request planes.
            ARKit pushes them to you as the user scans. The
            <span class="tag">ARCoachingOverlayView</span> (see Setup section)
            tells the user to move the phone around until a surface is found.
          </div>
        </div>
        <div class="expl" data-hl="12-18">
          <div class="expl-label">Convenience Planes</div>
          <h3>Auto-place on detected surfaces</h3>
          <p>
            Instead of writing delegate code, you can use
            <span class="tag">AnchorEntity(plane: .horizontal)</span>.
            RealityKit listens for plane-detection results from ARKit behind the
            scenes and automatically places the anchor on the first matching
            surface.
          </p>
          <p>
            <span class="tag">.horizontal</span> matches floors &amp; tables.
            <span class="tag">.vertical</span> matches walls. Adding
            <span class="tag">classification:</span> narrows it further &mdash;
            <span class="tag">.floor</span> ignores tables,
            <span class="tag">.table</span> ignores floors. LiDAR makes
            classification fast and accurate.
          </p>
          <div class="note">
            This is a convenience shortcut. Under the hood, it does the same
            thing as the delegate approach above &mdash; waiting for ARKit to
            detect an
            <span class="tag">ARPlaneAnchor</span> and attaching to it &mdash;
            but RealityKit handles the wiring for you.
          </div>
        </div>
        <div class="expl" data-hl="20-21">
          <div class="expl-label">World</div>
          <h3>Fixed point in 3D space</h3>
          <p>
            <span class="tag">AnchorEntity(world:)</span> locks to absolute
            coordinates without waiting for detection. Pass a
            <span class="tag">simd_float3</span> in meters from the session
            origin. Stays put as you move.
          </p>
        </div>
        <div class="expl" data-hl="23-24">
          <div class="expl-label">Raycast</div>
          <h3>Place where the user tapped</h3>
          <p>
            <span class="tag">AnchorEntity(raycastResult:)</span> creates an
            anchor at the exact 3D hit point with proper surface orientation.
          </p>
        </div>
        <div class="expl" data-hl="26-31">
          <div class="expl-label">Tracking</div>
          <h3>Camera &amp; image</h3>
          <p>
            <strong><span class="tag">.camera</span></strong> &mdash; the anchor
            follows the device. Content stays pinned in front of (or relative
            to) the phone as the user moves.
          </p>
          <p>
            <strong><span class="tag">.image</span></strong> &mdash; RealityKit
            scans the camera feed for a reference image you provide. You supply
            a <span class="tag">group</span> (the name of an AR Resource Group
            in your Xcode asset catalog) and a
            <span class="tag">name</span> (the specific image within it). When
            ARKit recognizes that image in the real world, it anchors your 3D
            content on top of it.
          </p>
          <div class="note">
            For <span class="tag">.image</span>, add an &ldquo;AR Resource
            Group&rdquo; in Xcode’s asset catalog and set the physical size of
            each image so ARKit knows how big it is.
          </div>
        </div>
        <div class="expl" data-hl="33-46">
          <div class="expl-label">Body</div>
          <h3>Attach content to a tracked person</h3>
          <p>
            <span class="tag">AnchorEntity(.body)</span> waits for ARKit’s
            body-tracking system to detect a person, then anchors content to
            their skeleton. Requires an
            <span class="tag">ARBodyTrackingConfiguration</span> instead of
            world tracking.
          </p>
          <p>
            The underlying <span class="tag">ARBodyAnchor</span> gives you a
            full <span class="tag">ARSkeleton3D</span> with named joints &mdash;
            <span class="tag">.head</span>, <span class="tag">.leftHand</span>,
            <span class="tag">.rightFoot</span>, etc. Look up a joint index with
            <span class="tag">ARSkeletonDefinition.defaultBody3D</span>, read
            its local transform, and multiply by the body anchor’s world
            transform for the joint’s world position.
          </p>
          <div class="note">
            Body tracking requires an A12+ chip and works best with the full
            body visible. It tracks one person at a time. The 3D skeleton has
            ~90 joints including fingers.
          </div>
        </div>
      </div>
      <div class="code-panel">
        <div class="code-bar">
          <div class="dots"><span></span><span></span><span></span></div>
          <div class="code-fname">Anchors.swift</div>
        </div>
        <div class="code-scroll" id="code-anchors"></div>
      </div>
    </div>

    <!-- ====== 03 DEPTH BUFFERS ====== -->
    <div class="section" data-section="depthbuf">
      <div class="explain-panel">
        <div class="divider" id="s-depth">
          <div class="num">03 — DEPTH BUFFERS</div>
          <h2>CVPixelBuffer &amp; Depth</h2>
          <p>
            LiDAR delivers per-pixel depth as CVPixelBuffers — here's how to
            lock, read, and use them.
          </p>
        </div>
        <div class="expl" data-hl="1-5">
          <div class="expl-label">Access</div>
          <h3>Getting the depth buffer</h3>
          <p>
            Each <span class="tag">ARFrame</span> carries a
            <span class="tag">sceneDepth</span> property (type
            <span class="tag">ARDepthData?</span>). Its
            <span class="tag">depthMap</span> is a
            <span class="tag">CVPixelBuffer</span> — an image-like 2D array
            where each pixel stores a <span class="tag">Float32</span>
            distance in meters from the camera.
          </p>
          <p>
            <span class="tag">smoothedSceneDepth</span> is the same format but
            temporally filtered — less flicker, better for rendering.
            <span class="tag">confidenceMap</span> stores
            <span class="tag">UInt8</span> values: 0 (low), 1 (medium), 2
            (high).
          </p>
        </div>
        <div class="expl" data-hl="7-12">
          <div class="expl-label">Lock &amp; Read</div>
          <h3>Lock the buffer before reading</h3>
          <p>
            <span class="tag">CVPixelBufferLockBaseAddress</span> pins the
            memory so the GPU doesn't overwrite it while you read. Always call
            <span class="tag">Unlock</span> when done.
          </p>
          <p>
            <span class="tag">CVPixelBufferGetWidth/Height</span> gives the
            resolution (typically 256×192 for LiDAR depth).
            <span class="tag">GetBaseAddress</span> returns a raw pointer to the
            float data.
          </p>
          <div class="note">
            The depth buffer is much lower resolution than the camera image. A
            256×192 depth map covers the full camera field of view — each pixel
            represents a larger area of the scene.
          </div>
        </div>
        <div class="expl" data-hl="14-19">
          <div class="expl-label">Read Pixels</div>
          <h3>Bind as Float32 and index</h3>
          <p>
            Cast the raw pointer to
            <span class="tag">UnsafeMutablePointer&lt;Float32&gt;</span>. Index
            with <span class="tag">y * width + x</span> to get the depth at any
            pixel. Values are in meters — <span class="tag">0.5</span> means
            50cm from the camera.
          </p>
        </div>
        <div class="expl" data-hl="21-27">
          <div class="expl-label">3D Point</div>
          <h3>Project a depth pixel into 3D</h3>
          <p>
            Combine the depth value with the camera's
            <span class="tag">intrinsics</span> (focal length &amp; principal
            point) and <span class="tag">viewMatrix</span> to unproject a 2D
            depth pixel into a 3D world-space point. This is how you turn the
            depth map into a point cloud.
          </p>
          <div class="note">
            <strong>Column-major indexing:</strong>
            <span class="tag">simd_float3x3</span> (and all SIMD matrix types in
            Swift) are stored <strong>column-major</strong> — the first
            subscript selects the <em>column</em>, the second selects the
            <em>row</em> within that column. So
            <span class="tag">intrinsics[0][0]</span> = column 0, row 0 =
            f<sub>x</sub>, and <span class="tag">intrinsics[1][1]</span> =
            column 1, row 1 = f<sub>y</sub>. This is the opposite of the
            <span class="tag">matrix[row][col]</span> convention you might
            expect from math textbooks or C 2D arrays. The same rule applies to
            every <span class="tag">simd_float4x4</span> transform you see in
            ARKit.
          </div>
        </div>
        <div class="expl" data-hl="21-27">
          <div class="expl-label">Use Cases</div>
          <h3>What you can build with depth</h3>
          <p>
            <strong>Proximity detection</strong> — sample the center pixel to
            warn when the user is too close to a wall. Compare
            <span class="tag">depthAt(cx, cy)</span> against a threshold.
          </p>
          <p>
            <strong>Occlusion</strong> — hide virtual objects behind real
            surfaces by comparing the object distance to the depth value at its
            screen position. RealityKit can do this automatically with
            <span class="tag"
              >ARView.Environment.SceneUnderstanding .occlusion</span
            >.
          </p>
          <p>
            <strong>Surface measurement</strong> — pick two screen points,
            unproject both through the depth map, then compute
            <span class="tag">simd_distance(p1, p2)</span> for a real-world
            ruler.
          </p>
          <p>
            <strong>Point cloud generation</strong> — iterate every depth pixel
            and unproject each one to build a dense 3D point cloud for scanning
            or export.
          </p>
        </div>
      </div>
      <div class="code-panel">
        <div class="code-bar">
          <div class="dots"><span></span><span></span><span></span></div>
          <div class="code-fname">DepthBuffer.swift</div>
        </div>
        <div class="code-scroll" id="code-depthbuf"></div>
      </div>
    </div>

    <!-- ====== 04 MODELS ====== -->
    <div class="section" data-section="usdz">
      <div class="explain-panel">
        <div class="divider" id="s-usdz">
          <div class="num">04 — MODELS &amp; SHAPES</div>
          <h2>Adding 3D Content</h2>
          <p>
            Load USDZ models or generate primitive shapes, and add them to the
            scene with physics and collision.
          </p>
        </div>
        <div class="expl" data-hl="1-4">
          <div class="expl-label">Primitives</div>
          <h3>Generate shapes in code</h3>
          <p>
            <span class="tag">MeshResource</span> can generate boxes, spheres,
            planes, and text without any external files. Combine with a
            <span class="tag">SimpleMaterial</span> to create a
            <span class="tag">ModelEntity</span>.
          </p>
        </div>
        <div class="expl" data-hl="6-11">
          <div class="expl-label">Centering</div>
          <h3>Primitives are centered at origin</h3>
          <p>
            A box with <span class="tag">size: 0.1</span> extends ±0.05 m from
            its center. On a floor anchor, half is underground. Fix by shifting
            <span class="tag">.position.y</span> up by half the height, or pass
            a raised <span class="tag">origin:</span> to
            <span class="tag">generateBox</span>.
          </p>
        </div>
        <div class="expl" data-hl="13-16">
          <div class="expl-label">USDZ Load</div>
          <h3>Load a model with async/await</h3>
          <p>
            <span class="tag">try await ModelEntity(named:)</span> loads a
            <span class="tag">.usdz</span> file from your Xcode project. Call
            <span class="tag">generateCollisionShapes</span> to make it
            interactive.
          </p>
        </div>
        <div class="expl" data-hl="18-23">
          <div class="expl-label">Gestures</div>
          <h3>Built-in drag, rotate &amp; scale</h3>
          <p>
            <span class="tag">installGestures(.all, for:)</span> gives the
            entity drag, two-finger rotation, and pinch-to-scale for free.
            Requires a collision shape on the entity. Pass individual options
            like <span class="tag">.translation</span> to limit to dragging
            only.
          </p>
        </div>
        <div class="expl" data-hl="25-27">
          <div class="expl-label">Add to Scene</div>
          <h3>Anchor and attach</h3>
          <p>
            Create an <span class="tag">AnchorEntity</span> to pin the model to
            a plane or world position, add the model as a child, then add the
            anchor to <span class="tag">arView.scene</span>.
          </p>
        </div>
      </div>
      <div class="code-panel">
        <div class="code-bar">
          <div class="dots"><span></span><span></span><span></span></div>
          <div class="code-fname">Models.swift</div>
        </div>
        <div class="code-scroll" id="code-usdz"></div>
      </div>
    </div>

    <!-- ====== 05 GESTURES ====== -->
    <div class="section" data-section="gestures">
      <div class="explain-panel">
        <div class="divider" id="s-gestures">
          <div class="num">05 — GESTURES</div>
          <h2>Built-in Entity Gestures</h2>
          <p>
            One line gives you drag, rotate, and pinch-to-scale. Capture the
            recognizers to observe or customize behavior.
          </p>
        </div>
        <div class="expl" data-hl="1-4">
          <div class="expl-label">Install</div>
          <h3>Enable gestures on an entity</h3>
          <p>
            <span class="tag">installGestures(.all, for:)</span> adds
            translation, rotation, and scale gesture recognizers. The entity
            must have a collision shape first. Use
            <span class="tag">.translation</span> alone to limit to drag only.
          </p>
        </div>
        <div class="expl" data-hl="6-10">
          <div class="expl-label">Observe</div>
          <h3>React to gesture events</h3>
          <p>
            <span class="tag">installGestures</span> returns an array of
            recognizers. Add a target to each one to observe position, rotation,
            or scale changes in real time.
          </p>
        </div>
        <div class="expl" data-hl="12-22">
          <div class="expl-label">Handle</div>
          <h3>Cast to the specific recognizer</h3>
          <p>
            Check the gesture type by casting to
            <span class="tag">EntityTranslationGestureRecognizer</span>,
            <span class="tag">EntityRotationGestureRecognizer</span>, or
            <span class="tag">EntityScaleGestureRecognizer</span>. Read
            <span class="tag">.entity</span> to access the entity being
            manipulated.
          </p>
          <div class="note">
            Gestures update the entity’s transform automatically. Your handler
            is for observation or side effects — you don’t need to move the
            entity yourself.
          </div>
        </div>
      </div>
      <div class="code-panel">
        <div class="code-bar">
          <div class="dots"><span></span><span></span><span></span></div>
          <div class="code-fname">Gestures.swift</div>
        </div>
        <div class="code-scroll" id="code-gestures"></div>
      </div>
    </div>

    <!-- ====== 06 COORDINATES ====== -->
    <div class="section" data-section="coordinates">
      <div class="explain-panel">
        <div class="divider" id="s-coords">
          <div class="num">06 — COORDINATE SYSTEM</div>
          <h2>Coordinates</h2>
          <p>
            How ARKit maps the real world into numbers — right-handed, in
            meters, Y pointing up.
          </p>
        </div>
        <div class="expl" data-hl="1-4">
          <div class="expl-label">Axes</div>
          <h3>Right-handed coordinate system</h3>
          <p>
            Everything in ARKit is in <strong>meters</strong>. The origin
            (0,0,0) is where the phone was when the session started.
          </p>
          <p>
            <span class="tag">+X</span> right, <span class="tag">+Y</span> up
            (against gravity), <span class="tag">+Z</span> toward you. Camera
            looks down <span class="tag">–Z</span>.
          </p>
          <div class="illust">
            <canvas id="scene-coords" width="420" height="280"></canvas>
          </div>
        </div>
        <div class="expl" data-hl="6-11">
          <div class="expl-label">4×4 Matrix</div>
          <h3>What is a transform matrix?</h3>
          <p>
            Every object in AR has a
            <span class="tag">simd_float4x4</span> &mdash; a grid of 16 numbers
            arranged in 4 columns. Don&rsquo;t panic &mdash; you only need to
            care about what each column <em>means</em>:
          </p>
          <div class="illust">
            <canvas id="scene-matrix" width="420" height="300"></canvas>
          </div>
          <p>
            Imagine gluing three tiny arrows to an object and writing down where
            each one points. That&rsquo;s what the first three columns store:
          </p>
          <p>
            <span class="tag">columns.0</span> &mdash;
            <strong style="color: #ff3b30">right arrow</strong> &mdash;
            &ldquo;which way is the object&rsquo;s right side?&rdquo;<br />
            <span class="tag">columns.1</span> &mdash;
            <strong style="color: #34c759">up arrow</strong> &mdash;
            &ldquo;which way is the object&rsquo;s top?&rdquo;<br />
            <span class="tag">columns.2</span> &mdash;
            <strong style="color: #007aff">forward arrow</strong> &mdash;
            &ldquo;which way is the object&rsquo;s front?&rdquo; (camera
            convention: it looks down &ndash;Z, so this arrow points
            <em>behind</em> the camera).
          </p>
          <p>
            <span class="tag">columns.3</span> &mdash;
            <strong style="color: #ff9500">position</strong> &mdash;
            &ldquo;where is the object?&rdquo; The x, y, z values are meters
            from the origin.
          </p>
          <p>
            <strong>Concrete example:</strong> a phone that&rsquo;s 2 m ahead,
            1.5 m up, turned 45&deg; to the right. Its matrix:
          </p>
          <div style="overflow-x: auto; margin: 0.8rem 0; max-width: 520px">
            <table
              style="
                border-collapse: collapse;
                font-family: 'JetBrains Mono', monospace;
                font-size: 0.82rem;
                width: 100%;
              "
            >
              <thead>
                <tr style="border-bottom: 2px solid var(--border)">
                  <th
                    style="
                      padding: 0.35rem 0.5rem;
                      text-align: left;
                      color: var(--txm);
                      font-weight: 500;
                    "
                  >
                    Row
                  </th>
                  <th
                    style="
                      padding: 0.35rem 0.5rem;
                      text-align: center;
                      color: #ff3b30;
                      font-weight: 600;
                    "
                  >
                    col 0<br /><span
                      style="font-size: 0.72rem; font-weight: 400"
                      >right</span
                    >
                  </th>
                  <th
                    style="
                      padding: 0.35rem 0.5rem;
                      text-align: center;
                      color: #34c759;
                      font-weight: 600;
                    "
                  >
                    col 1<br /><span
                      style="font-size: 0.72rem; font-weight: 400"
                      >up</span
                    >
                  </th>
                  <th
                    style="
                      padding: 0.35rem 0.5rem;
                      text-align: center;
                      color: #007aff;
                      font-weight: 600;
                    "
                  >
                    col 2<br /><span
                      style="font-size: 0.72rem; font-weight: 400"
                      >fwd (+Z)</span
                    >
                  </th>
                  <th
                    style="
                      padding: 0.35rem 0.5rem;
                      text-align: center;
                      color: #ff9500;
                      font-weight: 600;
                    "
                  >
                    col 3<br /><span
                      style="font-size: 0.72rem; font-weight: 400"
                      >position</span
                    >
                  </th>
                </tr>
              </thead>
              <tbody style="color: var(--tx)">
                <tr style="border-bottom: 1px solid var(--border-lt)">
                  <td style="padding: 0.3rem 0.5rem; color: var(--txm)">x</td>
                  <td style="padding: 0.3rem 0.5rem; text-align: center">
                    0.71
                  </td>
                  <td style="padding: 0.3rem 0.5rem; text-align: center">0</td>
                  <td style="padding: 0.3rem 0.5rem; text-align: center">
                    0.71
                  </td>
                  <td style="padding: 0.3rem 0.5rem; text-align: center">0</td>
                </tr>
                <tr style="border-bottom: 1px solid var(--border-lt)">
                  <td style="padding: 0.3rem 0.5rem; color: var(--txm)">y</td>
                  <td style="padding: 0.3rem 0.5rem; text-align: center">0</td>
                  <td style="padding: 0.3rem 0.5rem; text-align: center">1</td>
                  <td style="padding: 0.3rem 0.5rem; text-align: center">0</td>
                  <td style="padding: 0.3rem 0.5rem; text-align: center">
                    1.5
                  </td>
                </tr>
                <tr style="border-bottom: 1px solid var(--border-lt)">
                  <td style="padding: 0.3rem 0.5rem; color: var(--txm)">z</td>
                  <td style="padding: 0.3rem 0.5rem; text-align: center">
                    &minus;0.71
                  </td>
                  <td style="padding: 0.3rem 0.5rem; text-align: center">0</td>
                  <td style="padding: 0.3rem 0.5rem; text-align: center">
                    0.71
                  </td>
                  <td style="padding: 0.3rem 0.5rem; text-align: center">
                    &minus;2
                  </td>
                </tr>
                <tr>
                  <td style="padding: 0.3rem 0.5rem; color: var(--txm)">w</td>
                  <td
                    style="
                      padding: 0.3rem 0.5rem;
                      text-align: center;
                      color: var(--txm);
                    "
                  >
                    0
                  </td>
                  <td
                    style="
                      padding: 0.3rem 0.5rem;
                      text-align: center;
                      color: var(--txm);
                    "
                  >
                    0
                  </td>
                  <td
                    style="
                      padding: 0.3rem 0.5rem;
                      text-align: center;
                      color: var(--txm);
                    "
                  >
                    0
                  </td>
                  <td
                    style="
                      padding: 0.3rem 0.5rem;
                      text-align: center;
                      color: var(--txm);
                    "
                  >
                    1
                  </td>
                </tr>
              </tbody>
            </table>
          </div>
          <p>
            Each column reads top-to-bottom as
            <span class="tag">(x, y, z, w)</span>. So:
          </p>
          <p>
            <strong style="color: #ff3b30">col 0</strong> =
            <span class="tag">(0.71, 0, &minus;0.71)</span> &mdash; the
            &ldquo;right&rdquo; arrow has rotated 45&deg;. It&rsquo;s no longer
            pointing purely along +X because the phone turned.
          </p>
          <p>
            <strong style="color: #34c759">col 1</strong> =
            <span class="tag">(0, 1, 0)</span> &mdash; the &ldquo;up&rdquo;
            arrow still points straight up. The phone didn&rsquo;t tilt.
          </p>
          <p>
            <strong style="color: #007aff">col 2</strong> =
            <span class="tag">(0.71, 0, 0.71)</span> &mdash; the +Z arrow points
            behind-and-right of origin, matching the 45&deg; turn.
          </p>
          <p>
            <strong style="color: #ff9500">col 3</strong> =
            <span class="tag">(0, 1.5, &minus;2)</span> &mdash; the phone is at
            x=0, y=1.5&thinsp;m up, z=&minus;2&thinsp;m (2 m ahead, since
            &ndash;Z is forward).
          </p>
          <p>
            The <strong>w</strong> row is always
            <span class="tag">0, 0, 0, 1</span> for a standard rigid transform
            &mdash; you can ignore it.
          </p>
        </div>
        <div class="expl" data-hl="13-17">
          <div class="expl-label">Camera</div>
          <h3>Camera data every frame</h3>
          <p>
            Every frame, <span class="tag">ARCamera</span> tells you where the
            phone is, which way it&rsquo;s pointing, and how its lens works.
            Four properties cover everything:
          </p>
          <p>
            <strong><span class="tag">transform</span></strong> — a 4×4 matrix
            that says &ldquo;the phone is <em>here</em>, pointing
            <em>this way</em>.&rdquo; It&rsquo;s the same kind of matrix every
            entity has. Column 3 is the phone&rsquo;s position in meters.
          </p>
          <p>
            <strong><span class="tag">eulerAngles</span></strong> — three plain
            numbers: pitch (tilt up/down), yaw (turn left/right), roll (twist).
            Great when you just want to know &ldquo;is the user looking at the
            ceiling?&rdquo; without doing matrix math.
          </p>
          <p>
            <strong><span class="tag">intrinsics</span></strong> — describes the
            physical lens. <span class="tag">fx</span>,
            <span class="tag">fy</span> are the focal length in pixels (how
            &ldquo;zoomed in&rdquo; the camera is). <span class="tag">cx</span>,
            <span class="tag">cy</span> are the center of the image. You need
            these to convert a screen tap into a 3D ray, or to project a 3D
            point back to screen pixels.
          </p>
          <p>
            <strong><span class="tag">projectionMatrix</span></strong> — the
            magic matrix that squashes 3D space onto a flat screen image. It
            encodes the lens&rsquo;s field of view and near/far clipping planes.
            Combined with the <span class="tag">viewMatrix</span>, it converts
            any 3D world point into a 2D screen coordinate.
          </p>
        </div>
        <div class="expl" data-hl="19-20">
          <div class="expl-label">The Matrix</div>
          <h3>Inside the projection matrix</h3>
          <p>
            The <span class="tag">projectionMatrix</span> is a 4&times;4 matrix
            that encodes how the camera lens distorts 3D space onto a flat
            image. Its structure looks like this:
          </p>
          <div
            class="note"
            style="
              font-family: 'JetBrains Mono', monospace;
              font-size: 0.85rem;
              line-height: 1.9;
              white-space: pre;
              overflow-x: auto;
            "
          >
            &#x250C; &#x2510; &#x2502; fx 0 0 0 &#x2502; &#x2502; 0 fy 0 0
            &#x2502; &#x2502; 0 0 A B &#x2502; &#x2502; 0 0 &ndash;1 0 &#x2502;
            &#x2514; &#x2518;
          </div>
          <p>
            <span class="tag">fx</span>, <span class="tag">fy</span> &mdash;
            scale X and Y based on the field of view. A narrower FOV means
            larger values (more &ldquo;zoom&rdquo;).
          </p>
          <p>
            <span class="tag">A</span>, <span class="tag">B</span> &mdash;
            encode the near and far clipping planes. They remap depth into the
            &ndash;1&hellip;+1 range so the GPU knows what&rsquo;s visible.
          </p>
          <p>
            <span class="tag">&ndash;1</span> in row 4 &mdash; this is the
            perspective trick. It copies the Z depth into the
            <span class="tag">w</span> component, so when you divide by
            <span class="tag">w</span> later, far-away objects shrink.
          </p>
          <div class="note">
            <strong>In short:</strong> multiplying a 3D point by this matrix
            gives a 4D &ldquo;clip&rdquo; vector. Dividing by its
            <span class="tag">w</span> collapses it to 2D &mdash; that&rsquo;s
            perspective projection in one multiply + one divide.
          </div>
        </div>
        <div class="expl" data-hl="19-25">
          <div class="expl-label">Projection</div>
          <h3>Project a 3D point onto screen</h3>
          <p>
            Say you placed a virtual cube at world position
            <span class="tag">(0.5, 0.3, -2.0)</span> and want to draw a SwiftUI
            label on top of it. Here&rsquo;s what happens, step by step:
          </p>
          <p>
            <strong>1. World → Camera space.</strong>
            The <span class="tag">viewMatrix</span> is the inverse of the
            camera&rsquo;s transform. Multiplying repositions the point as if
            the camera were at the origin looking down &ndash;Z. Result: a
            <span class="tag">simd_float4</span> in camera-local coords.
          </p>
          <p>
            <strong>2. Camera → Clip space.</strong>
            Multiply by <span class="tag">projectionMatrix</span>. This applies
            perspective &mdash; things farther away shrink. You get a
            4-component vector <span class="tag">(x, y, z, w)</span> where
            <span class="tag">w</span> encodes depth.
          </p>
          <p>
            <strong>3. Perspective divide.</strong>
            Divide every component by <span class="tag">w</span>:
            <span class="tag">ndc = clip / clip.w</span>. Now x and y range from
            <span class="tag">&ndash;1</span> to <span class="tag">+1</span>.
            This is called Normalized Device Coordinates (NDC) &mdash; center of
            screen is (0, 0).
          </p>
          <p>
            <strong>4. NDC → Screen pixels.</strong>
            Map the &ndash;1…+1 range to actual screen size:<br />
            <span class="tag">screenX = (ndc.x + 1) × 0.5 × width</span><br />
            <span class="tag">screenY = (1 &ndash; ndc.y) × 0.5 × height</span>
            (Y is flipped because screen Y goes downward).
          </p>
          <div class="note">
            <strong>Concrete example:</strong> If your clip result is
            <span class="tag">(1.2, -0.8, 3.1, 4.0)</span>, dividing by
            <span class="tag">w=4.0</span> gives NDC
            <span class="tag">(0.3, -0.2, …)</span>. On a 390×844 screen:
            <span class="tag">screenX = (0.3+1)×0.5×390 = 253</span>,
            <span class="tag">screenY = (1+0.2)×0.5×844 = 506</span>.
            That&rsquo;s where you place your label.
          </div>
        </div>
      </div>
      <div class="code-panel">
        <div class="code-bar">
          <div class="dots"><span></span><span></span><span></span></div>
          <div class="code-fname">Coordinates.swift</div>
        </div>
        <div class="code-scroll" id="code-coordinates"></div>
      </div>
    </div>

    <!-- ====== 06 SPAWNING ====== -->
    <div class="section" data-section="spawning">
      <div class="explain-panel">
        <div class="divider" id="s-spawn">
          <div class="num">07 — SPAWNING ON THE FLOOR</div>
          <h2>1 m in Front, on the Floor</h2>
          <p>
            Compute a point one meter ahead of the camera, raycast straight down
            to find the floor, and place a model there.
          </p>
        </div>
        <div class="expl" data-hl="1-8">
          <div class="expl-label">The Matrix</div>
          <h3>Reading the camera transform</h3>
          <p>
            <span class="tag">camera.transform</span> is a
            <span class="tag">simd_float4x4</span> — the same 4×4 matrix
            explained in the Coordinates section. Two columns matter here:
          </p>
          <p>
            <strong><span class="tag">columns.2</span></strong> — the
            camera&rsquo;s +Z direction. In ARKit, the camera looks down
            <strong>&ndash;Z</strong>, so column 2 actually points
            <em>behind</em> you. That&rsquo;s why we
            <strong>subtract</strong> it to move forward.
          </p>
          <p>
            <strong><span class="tag">columns.3</span></strong> — the
            camera&rsquo;s position in world space (x, y, z in meters).
          </p>
          <div class="note">
            Think of it as: <strong>ahead = position &ndash; forward</strong>.
            Subtracting the &ldquo;backward&rdquo; vector from position gives
            you a point 1 m in front of the camera.
          </div>
        </div>
        <div class="expl" data-hl="10-15">
          <div class="expl-label">1 m Ahead</div>
          <h3>position – forward = ahead</h3>
          <p>
            Since column 2 (the blue arrow) points <em>behind</em> the camera,
            <strong>subtracting</strong> it from the position pushes the point 1
            m in the direction you're looking.
          </p>
          <p>
            <span class="tag">SIMD3&lt;Float&gt;</span> extracts just
            <strong>x, y, z</strong> from a simd_float4 column, dropping the w
            component so you get a plain 3D point.
          </p>
        </div>
        <div class="expl" data-hl="17-23">
          <div class="expl-label">Raycast Down</div>
          <h3>Find the floor beneath that point</h3>
          <p>
            ARRaycastQuery lets you cast an arbitrary ray — here from the point
            1 m ahead straight [0, -1, 0] (down). Limit to .estimatedPlane +
            .horizontal so it only hits floors and tables.
          </p>
        </div>
        <div class="expl" data-hl="25-32">
          <div class="expl-label">Spawn</div>
          <h3>Place the model at the hit</h3>
          <p>
            Load a .usdz, build a translation matrix from the hit point so the
            model sits on the floor. Create an AnchorEntity at that transform
            and add it to the scene.
          </p>
          <div class="note">
            generateCollisionShapes is required for the entity to be tappable or
            draggable later.
          </div>
        </div>
      </div>
      <div class="code-panel">
        <div class="code-bar">
          <div class="dots"><span></span><span></span><span></span></div>
          <div class="code-fname">SpawnOnFloor.swift</div>
        </div>
        <div class="code-scroll" id="code-spawning"></div>
      </div>
    </div>

    <!-- ====== 07 KINEMATIC ====== -->
    <div class="section" data-section="kinematic">
      <div class="explain-panel">
        <div class="divider" id="s-kinematic">
          <div class="num">08 — KINEMATIC MOVEMENT</div>
          <h2>Move Each Frame</h2>
          <p>
            Update an entity's position every frame to slide it toward a
            waypoint without physics.
          </p>
        </div>
        <div class="expl" data-hl="1-2">
          <div class="expl-label">Delta Time</div>
          <h3>Frame-rate-independent movement</h3>
          <p>
            Inside the delegate
            <span class="tag">session(_:didUpdate:)</span> callback, compute
            <span class="tag">dt</span> from the frame timestamp so movement
            speed stays constant regardless of frame rate.
          </p>
        </div>
        <div class="expl" data-hl="3-5">
          <div class="expl-label">Steer</div>
          <h3>Move toward a waypoint</h3>
          <p>
            Normalize the direction from the entity to the waypoint, scale by
            <span class="tag">speed * dt</span>, and add to
            <span class="tag">.position</span>. The entity glides smoothly
            without a physics body.
          </p>
          <div class="note">
            For rotation, slerp
            <span class="tag">.orientation</span> toward the movement direction
            each frame.
          </div>
        </div>
      </div>
      <div class="code-panel">
        <div class="code-bar">
          <div class="dots"><span></span><span></span><span></span></div>
          <div class="code-fname">KinematicMove.swift</div>
        </div>
        <div class="code-scroll" id="code-kinematic"></div>
      </div>
    </div>

    <!-- ====== JOYSTICK ====== -->
    <div class="section" data-section="joystick">
      <div class="explain-panel">
        <div class="divider" id="s-joystick">
          <div class="num">08b — CAMERA-RELATIVE JOYSTICK</div>
          <h2>Joystick Moves Relative to Camera</h2>
          <p>
            A virtual joystick pushes the character in the direction the camera
            is facing — not in fixed world axes.
          </p>
        </div>
        <div class="expl" data-hl="1-6">
          <div class="expl-label">Camera Vectors</div>
          <h3>Extract forward &amp; right from the camera</h3>
          <p>
            The camera's 4×4 transform matrix encodes its orientation.
            <span class="tag">columns.2</span> is the local Z axis (the
            direction the camera faces is <em>negative</em> Z), and
            <span class="tag">columns.0</span> is the local X axis (camera
            right). We project both onto the XZ ground plane by zeroing their Y
            component and re-normalizing — this gives us flat "forward" and
            "right" vectors the character can move along.
          </p>
          <div class="note">
            Projecting onto XZ means the character stays on the ground plane
            regardless of whether the user is looking up or down.
          </div>
        </div>
        <div class="expl" data-hl="8-10">
          <div class="expl-label">Compose</div>
          <h3>Combine joystick axes with camera directions</h3>
          <p>
            The joystick gives a normalized
            <span class="tag">(width, height)</span> in the range −1…1.
            <span class="tag">width</span> maps to the camera's
            <strong>right</strong> vector and
            <span class="tag">height</span> (negated because SwiftUI Y points
            down) maps to the camera's <strong>forward</strong> vector. Adding
            them produces a single world-space direction.
          </p>
        </div>
        <div class="expl" data-hl="12-21">
          <div class="expl-label">Apply</div>
          <h3>Move the character each frame</h3>
          <p>
            In the scene update callback, read the joystick value, compute the
            camera-relative direction, scale by
            <span class="tag">moveSpeed × dt</span>, and add to the character's
            <span class="tag">worldPosition</span>. The character always runs
            the way the player expects — joystick up means away from the camera,
            joystick right means screen-right.
          </p>
          <div class="note">
            Wall collision can be added by raycasting in the move direction
            before applying the displacement.
          </div>
        </div>
      </div>
      <div class="code-panel">
        <div class="code-bar">
          <div class="dots"><span></span><span></span><span></span></div>
          <div class="code-fname">CameraRelativeMove.swift</div>
        </div>
        <div class="code-scroll" id="code-joystick"></div>
      </div>
    </div>

    <!-- ====== 08 DRAG ====== -->
    <div class="section" data-section="dragging">
      <div class="explain-panel">
        <div class="divider" id="s-drag">
          <div class="num">09 — DRAG INTERACTION</div>
          <h2>Tap &amp; Drag</h2>
          <p>
            Let the user grab an entity with their finger and slide it across
            the floor in real time.
          </p>
        </div>
        <div class="expl" data-hl="1-2">
          <div class="expl-label">Setup</div>
          <h3>Track which entity is grabbed</h3>
          <p>
            Store the dragged entity in a
            <span class="tag">dragEntity</span> optional so the
            <span class="tag">.changed</span> handler knows which object to
            move.
          </p>
        </div>
        <div class="expl" data-hl="3-7">
          <div class="expl-label">Began</div>
          <h3>Hit-test on finger down</h3>
          <p>
            On <span class="tag">.began</span>, call
            <span class="tag">arView.entity(at:)</span> to find the entity under
            the finger. Cast to <span class="tag">ModelEntity</span> so you can
            move it.
          </p>
        </div>
        <div class="expl" data-hl="8-13">
          <div class="expl-label">Changed</div>
          <h3>Raycast each drag frame</h3>
          <p>
            On <span class="tag">.changed</span>, raycast the current finger
            location to the floor. Use
            <span class="tag">setPosition(_:relativeTo: nil)</span>
            to snap the entity to the new world-space hit point.
          </p>
        </div>
        <div class="expl" data-hl="14-14">
          <div class="expl-label">End</div>
          <h3>Release the entity</h3>
          <p>
            On any other state (<span class="tag">.ended</span>,
            <span class="tag">.cancelled</span>), nil out
            <span class="tag">dragEntity</span> to stop tracking.
          </p>
        </div>
      </div>
      <div class="code-panel">
        <div class="code-bar">
          <div class="dots"><span></span><span></span><span></span></div>
          <div class="code-fname">DragEntity.swift</div>
        </div>
        <div class="code-scroll" id="code-dragging"></div>
      </div>
    </div>

    <!-- ====== 06 RAYCASTING ====== -->
    <div class="section" data-section="raycasting">
      <div class="explain-panel">
        <div class="divider" id="s-raycasting">
          <div class="num">11 — RAYCASTING</div>
          <h2>Raycasting</h2>
          <p>Shoot rays from screen taps to find real-world surfaces.</p>
        </div>
        <div class="expl" data-hl="1-6">
          <div class="expl-label">Quick Raycast</div>
          <h3>Screen tap → 3D surface</h3>
          <p>
            <span class="tag">.estimatedPlane</span> = LiDAR superpower. Finds
            surfaces without waiting for plane detection.
          </p>
        </div>
        <div class="expl" data-hl="7-11">
          <div class="expl-label">Placing</div>
          <h3>Anchor at the hit point</h3>
          <p>
            The result's <span class="tag">worldTransform</span> includes
            surface orientation so objects sit flush on angled surfaces.
          </p>
        </div>
        <div class="expl" data-hl="13-23">
          <div class="expl-label">Tracked</div>
          <h3>Continuous refinement</h3>
          <p>
            <span class="tag">trackedRaycast</span> keeps alive and calls your
            closure repeatedly as the hit refines. Great for preview placement.
            Call <span class="tag">stopTracking()</span> to finalize.
          </p>
        </div>
      </div>
      <div class="code-panel">
        <div class="code-bar">
          <div class="dots"><span></span><span></span><span></span></div>
          <div class="code-fname">Raycasting.swift</div>
        </div>
        <div class="code-scroll" id="code-raycasting"></div>
      </div>
    </div>

    <!-- ====== 07 HIT TESTING ====== -->
    <div class="section" data-section="entityhits">
      <div class="explain-panel">
        <div class="divider" id="s-hits">
          <div class="num">12 — HIT TESTING</div>
          <h2>Entity Hit Testing</h2>
          <p>
            Detect taps on virtual objects — separate from real-world
            raycasting.
          </p>
        </div>
        <div class="expl" data-hl="1-3">
          <div class="expl-label">Screen Hits</div>
          <h3>Did they tap a virtual object?</h3>
          <p>
            <span class="tag">hitTest()</span> only finds virtual entities (not
            real surfaces). Entities must have collision shapes from
            <span class="tag">generateCollisionShapes</span>.
          </p>
        </div>
        <div class="expl" data-hl="5-10">
          <div class="expl-label">Hit Data</div>
          <h3>Entity, distance, position, normal</h3>
          <p>
            Each <span class="tag">CollisionCastHit</span> gives: the
            <span class="tag">entity</span>,
            <span class="tag">distance</span> from ray,
            <span class="tag">position</span> in world space, and
            <span class="tag">normal</span> (surface direction at hit — useful
            for aligning things flush).
          </p>
        </div>
        <div class="expl" data-hl="12-19">
          <div class="expl-label">3D Raycast</div>
          <h3>Cast from any point, any direction</h3>
          <p>
            <span class="tag">scene.raycast()</span> shoots from a 3D point (not
            the screen). Here: from 1m up, straight down.
            <span class="tag">length: 10.0</span> limits to 10 meters.
          </p>
        </div>
      </div>
      <div class="code-panel">
        <div class="code-bar">
          <div class="dots"><span></span><span></span><span></span></div>
          <div class="code-fname">HitTesting.swift</div>
        </div>
        <div class="code-scroll" id="code-entityhits"></div>
      </div>
    </div>

    <!-- ====== 13 INTERACTION METHODS ====== -->
    <div class="section" data-section="interactions">
      <div class="explain-panel">
        <div class="divider" id="s-interactions">
          <div class="num">13 — INTERACTION METHODS</div>
          <h2>Three Ways to Interact</h2>
          <p>
            RealityKit gives you three overlapping tools for user interaction.
            Each operates at a different level.
          </p>
        </div>
        <div class="expl" data-hl="1-4">
          <div class="expl-label">entity(at:)</div>
          <h3>Manual hit-test against virtual objects</h3>
          <p>
            <span class="tag">arView.entity(at:)</span> returns the
            <span class="tag">Entity</span> under a screen point. You decide
            what to do — delete it, highlight it, show a menu. Requires
            <span class="tag">generateCollisionShapes</span>.
          </p>
          <div class="note">
            Hits <strong>virtual</strong> entities only — not the real world.
          </div>
        </div>
        <div class="expl" data-hl="6-9">
          <div class="expl-label">installGestures</div>
          <h3>Automatic drag, rotate &amp; scale</h3>
          <p>
            <span class="tag">installGestures(.all, for:)</span> adds gesture
            recognizers that move the entity for you. No extra code needed — the
            entity becomes interactive immediately.
          </p>
          <div class="note">
            Also hits <strong>virtual</strong> collision shapes. Great when you
            just want manipulation with zero logic.
          </div>
        </div>
        <div class="expl" data-hl="11-16">
          <div class="expl-label">raycast</div>
          <h3>Find real-world surfaces</h3>
          <p>
            <span class="tag">arView.raycast(from:allowing:alignment:)</span>
            shoots a ray into the <strong>real world</strong> — ARKit planes and
            LiDAR mesh. Returns a <span class="tag">worldTransform</span> where
            you can place new content.
          </p>
          <div class="note">
            This is how tap-to-place works: raycast to find the floor, then
            spawn a model there.
          </div>
        </div>
        <div class="expl" data-hl="18-22">
          <div class="expl-label">Combine</div>
          <h3>Use them together</h3>
          <p>
            A typical flow: <span class="tag">raycast</span> to find the floor
            and place a model, then <span class="tag">installGestures</span> so
            the user can drag it around, and
            <span class="tag">entity(at:)</span> on long-press to delete or
            configure it.
          </p>
        </div>
      </div>
      <div class="code-panel">
        <div class="code-bar">
          <div class="dots"><span></span><span></span><span></span></div>
          <div class="code-fname">Interactions.swift</div>
        </div>
        <div class="code-scroll" id="code-interactions"></div>
      </div>
    </div>

    <!-- ====== 14 DELEGATE ====== -->
    <div class="section" data-section="delegate">
      <div class="explain-panel">
        <div class="divider" id="s-delegate">
          <div class="num">14 — DELEGATE</div>
          <h2>ARSessionDelegate</h2>
          <p>
            Per-frame callbacks for camera data, depth maps, and anchor
            discovery.
          </p>
        </div>
        <div class="expl" data-hl="1-2">
          <div class="expl-label">Per-Frame</div>
          <h3>Called ~60× per second</h3>
          <p>
            <span class="tag">didUpdate frame</span> fires every camera frame.
            <span class="tag">frame.camera.transform</span> = phone's current
            position/orientation. The most-used value in AR.
          </p>
        </div>
        <div class="expl" data-hl="3-6">
          <div class="expl-label">Depth</div>
          <h3>Per-pixel distance measurements</h3>
          <p>
            <span class="tag">depthMap</span> = CVPixelBuffer, each pixel =
            meters from camera. <span class="tag">smoothedSceneDepth</span> =
            filtered (less noise). <span class="tag">confidenceMap</span> = 0
            (low), 1 (med), 2 (high).
          </p>
        </div>
        <div class="expl" data-hl="9-17">
          <div class="expl-label">Anchors</div>
          <h3>New planes and meshes</h3>
          <p>
            <span class="tag">didAdd anchors</span> fires on discovery. Cast to
            <span class="tag">ARPlaneAnchor</span> (surface + classification) or
            <span class="tag">ARMeshAnchor</span> (raw LiDAR mesh geometry).
          </p>
        </div>
      </div>
      <div class="code-panel">
        <div class="code-bar">
          <div class="dots"><span></span><span></span><span></span></div>
          <div class="code-fname">Delegate.swift</div>
        </div>
        <div class="code-scroll" id="code-delegate"></div>
      </div>
    </div>

    <!-- ====== 09 SCENE ====== -->
    <div class="section" data-section="scene">
      <div class="explain-panel">
        <div class="divider" id="s-scene">
          <div class="num">15 — SCENE UNDERSTANDING</div>
          <h2>Occlusion &amp; Physics</h2>
          <p>
            Virtual objects interact realistically with the real world using
            LiDAR.
          </p>
        </div>
        <div class="expl" data-hl="1-6">
          <div class="expl-label">Three Powers</div>
          <h3>Occlusion, physics, lighting</h3>
        </div>
        <div class="expl" data-hl="8-12">
          <div class="expl-label">Occlusion</div>
          <h3>Invisible geometry that hides</h3>
          <p>
            <span class="tag">OcclusionMaterial</span> = invisible but blocks
            rendering behind it. Make invisible walls matching real walls.
          </p>
        </div>
        <div class="expl" data-hl="14-21">
          <div class="expl-label">Debug</div>
          <h3>Visualize what ARKit sees</h3>
          <p>
            <span class="tag">.showSceneUnderstanding</span> = wireframe mesh.
            <span class="tag">.showWorldOrigin</span> = axes.
            <span class="tag">.showFeaturePoints</span> = point cloud. Essential
            for debugging.
          </p>
        </div>
      </div>
      <div class="code-panel">
        <div class="code-bar">
          <div class="dots"><span></span><span></span><span></span></div>
          <div class="code-fname">SceneUnderstanding.swift</div>
        </div>
        <div class="code-scroll" id="code-scene"></div>
      </div>
    </div>

    <!-- ====== 10 TAP ====== -->
    <div class="section" data-section="tap">
      <div class="explain-panel">
        <div class="divider" id="s-tap">
          <div class="num">16 — TAP TO PLACE</div>
          <h2>Tap-to-Place</h2>
          <p>
            The most common pattern — tap a surface to place a model with
            gestures.
          </p>
        </div>
        <div class="expl" data-hl="1-3">
          <div class="expl-label">Handler</div>
          <h3>Gesture recognizer callback</h3>
          <p>Gets the tap's 2D position for hit testing and raycasting.</p>
        </div>
        <div class="expl" data-hl="5-9">
          <div class="expl-label">Entity First</div>
          <h3>Check existing objects first</h3>
          <p>
            Always check entity hits before world raycasting. If an object was
            tapped, handle it and return early.
          </p>
        </div>
        <div class="expl" data-hl="11-20">
          <div class="expl-label">Place</div>
          <h3>Raycast → Load → Anchor → Gestures</h3>
          <p>
            Find the surface, load the model, generate collision shapes, anchor
            it, and add gestures.
          </p>
          <div class="illust">
            <svg viewBox="0 0 420 65">
              <rect width="420" height="65" fill="#fafafa" />
              <text
                x="20"
                y="18"
                font-family="Inter,sans-serif"
                font-size="10"
                font-weight="600"
                fill="#1a1a1a"
              >
                installGestures(.all) enables:
              </text>
              <rect
                x="20"
                y="30"
                width="110"
                height="26"
                rx="6"
                fill="#e8f0ff"
                stroke="#0066ff"
                stroke-width="1"
              />
              <text
                x="75"
                y="47"
                text-anchor="middle"
                font-family="Inter,sans-serif"
                font-size="10"
                fill="#0066ff"
              >
                ☝️ Drag
              </text>
              <rect
                x="145"
                y="30"
                width="130"
                height="26"
                rx="6"
                fill="#dcfce7"
                stroke="#16a34a"
                stroke-width="1"
              />
              <text
                x="210"
                y="47"
                text-anchor="middle"
                font-family="Inter,sans-serif"
                font-size="10"
                fill="#16a34a"
              >
                ✌️ Two-finger rotate
              </text>
              <rect
                x="290"
                y="30"
                width="115"
                height="26"
                rx="6"
                fill="#f3e8ff"
                stroke="#7c3aed"
                stroke-width="1"
              />
              <text
                x="347"
                y="47"
                text-anchor="middle"
                font-family="Inter,sans-serif"
                font-size="10"
                fill="#7c3aed"
              >
                🤏 Pinch scale
              </text>
            </svg>
          </div>
        </div>
      </div>
      <div class="code-panel">
        <div class="code-bar">
          <div class="dots"><span></span><span></span><span></span></div>
          <div class="code-fname">TapToPlace.swift</div>
        </div>
        <div class="code-scroll" id="code-tap"></div>
      </div>
    </div>

    <!-- ====== 11 MESH ====== -->
    <div class="section" data-section="mesh">
      <div class="explain-panel">
        <div class="divider" id="s-mesh">
          <div class="num">17 — MESH EXTRACTION</div>
          <h2>LiDAR Mesh</h2>
          <p>
            Raw triangle mesh: vertices, faces, normals, classification labels.
          </p>
        </div>
        <div class="expl" data-hl="1-4">
          <div class="expl-label">Chunks</div>
          <h3>Mesh arrives in pieces</h3>
          <p>
            Each <span class="tag">ARMeshAnchor</span> covers part of the
            environment. Refines over time via
            <span class="tag">didUpdate</span>.
          </p>
        </div>
        <div class="expl" data-hl="6-8">
          <div class="expl-label">Geometry</div>
          <h3>Vertices, faces, normals</h3>
          <p>
            <span class="tag">vertices</span> = 3D points.
            <span class="tag">faces</span> = triangle indices.
            <span class="tag">normals</span> = surface direction per vertex.
          </p>
        </div>
        <div class="expl" data-hl="9-11">
          <div class="expl-label">Labels</div>
          <h3>Per-face classification</h3>
          <div class="illust">
            <svg viewBox="0 0 420 65">
              <rect width="420" height="65" fill="#fafafa" />
              <text
                x="15"
                y="16"
                font-family="Inter,sans-serif"
                font-size="10"
                font-weight="600"
                fill="#1a1a1a"
              >
                Classification values
              </text>
              <g font-family="JetBrains Mono,monospace" font-size="9">
                <rect
                  x="10"
                  y="26"
                  width="42"
                  height="20"
                  rx="4"
                  fill="#f5f5f5"
                  stroke="#e5e5e5"
                  stroke-width=".8"
                />
                <text x="31" y="40" text-anchor="middle" fill="#a0a0a0">
                  0 none
                </text>
                <rect
                  x="57"
                  y="26"
                  width="42"
                  height="20"
                  rx="4"
                  fill="#fef2f2"
                  stroke="#dc2626"
                  stroke-width=".8"
                />
                <text x="78" y="40" text-anchor="middle" fill="#dc2626">
                  1 wall
                </text>
                <rect
                  x="104"
                  y="26"
                  width="46"
                  height="20"
                  rx="4"
                  fill="#dcfce7"
                  stroke="#16a34a"
                  stroke-width=".8"
                />
                <text x="127" y="40" text-anchor="middle" fill="#16a34a">
                  2 floor
                </text>
                <rect
                  x="155"
                  y="26"
                  width="52"
                  height="20"
                  rx="4"
                  fill="#e8f0ff"
                  stroke="#0066ff"
                  stroke-width=".8"
                />
                <text x="181" y="40" text-anchor="middle" fill="#0066ff">
                  3 ceiling
                </text>
                <rect
                  x="212"
                  y="26"
                  width="46"
                  height="20"
                  rx="4"
                  fill="#fff7ed"
                  stroke="#ea580c"
                  stroke-width=".8"
                />
                <text x="235" y="40" text-anchor="middle" fill="#ea580c">
                  4 table
                </text>
                <rect
                  x="263"
                  y="26"
                  width="42"
                  height="20"
                  rx="4"
                  fill="#f3e8ff"
                  stroke="#7c3aed"
                  stroke-width=".8"
                />
                <text x="284" y="40" text-anchor="middle" fill="#7c3aed">
                  5 seat
                </text>
                <rect
                  x="310"
                  y="26"
                  width="42"
                  height="20"
                  rx="4"
                  fill="#ecfeff"
                  stroke="#0891b2"
                  stroke-width=".8"
                />
                <text x="331" y="40" text-anchor="middle" fill="#0891b2">
                  6 door
                </text>
                <rect
                  x="357"
                  y="26"
                  width="50"
                  height="20"
                  rx="4"
                  fill="#fef9c3"
                  stroke="#a16207"
                  stroke-width=".8"
                />
                <text x="382" y="40" text-anchor="middle" fill="#a16207">
                  7 window
                </text>
              </g>
            </svg>
          </div>
        </div>
        <div class="expl" data-hl="13-14">
          <div class="expl-label">World</div>
          <h3>Convert to world coordinates</h3>
          <p>
            Vertices are in local space. Multiply by
            <span class="tag">meshAnchor.transform</span> for world coordinates.
          </p>
        </div>
      </div>
      <div class="code-panel">
        <div class="code-bar">
          <div class="dots"><span></span><span></span><span></span></div>
          <div class="code-fname">MeshExtraction.swift</div>
        </div>
        <div class="code-scroll" id="code-mesh"></div>
      </div>
    </div>

    <!-- ====== 18 OUTLINES ====== -->
    <div class="section" data-section="outline">
      <div class="explain-panel">
        <div class="divider" id="s-outline">
          <div class="num">18 — PLANE OUTLINES</div>
          <h2>Outlining Detected Planes</h2>
          <p>
            Draw thin white borders around detected surfaces. Each plane anchor
            has a polygon boundary — we turn every edge into a narrow rectangle
            to render a visible outline.
          </p>
        </div>
        <div class="expl" data-hl="1-4">
          <div class="expl-label">Delegate</div>
          <h3>Respond to plane anchors</h3>
          <p>
            Implement <span class="tag">ARSessionDelegate</span> to receive
            <span class="tag">didAdd</span> and
            <span class="tag">didUpdate</span> callbacks for plane anchors. Each
            time a horizontal plane is detected or refined, rebuild its outline.
          </p>
        </div>
        <div class="expl" data-hl="6-14">
          <div class="expl-label">Boundary</div>
          <h3>Walk the boundary vertices</h3>
          <p>
            <span class="tag">planeAnchor.geometry.boundaryVertices</span>
            gives you an array of 3D points that trace the detected
            surface&rsquo;s outline &mdash; like connecting the dots around a
            table or floor region. Each consecutive pair of points
            <span class="tag">(v0, v1)</span> forms one edge of the polygon.
          </p>
          <p>
            A line between two points has no width &mdash; you can't render it
            as a filled surface. To draw a visible edge, we need to expand each
            edge into a thin rectangle (a quad). That's where the perpendicular
            offset comes in.
          </p>
          <div class="illust">
            <canvas id="scene-outlines" width="420" height="280"></canvas>
          </div>
          <div class="note">
            The boundary is in the plane's local space. Apply
            <span class="tag">planeAnchor.transform</span> when positioning the
            outline entity in world space.
          </div>
        </div>
        <div class="expl" data-hl="16-28">
          <div class="expl-label">Quad Strip</div>
          <h3>Expanding each edge into a rectangle</h3>
          <p>
            Imagine you&rsquo;re standing on a line painted on the ground,
            looking along it. "Perpendicular" just means
            <strong>sideways</strong> &mdash; the direction at a right angle to
            the line. We need that direction so we can push each edge outward on
            both sides to give it thickness.
          </p>
          <p>
            <strong>Step by step for each edge:</strong>
          </p>
          <p>
            <strong>1.</strong> Compute the edge direction:
            <span class="tag">edgeDir = normalize(v1 - v0)</span>. This points
            along the edge.
          </p>
          <p>
            <strong>2.</strong> Find the sideways direction:
            <span class="tag">right = cross(edgeDir, up)</span>. The cross
            product of two vectors gives a third vector perpendicular to both.
            Crossing the edge direction with &ldquo;up&rdquo;
            <span class="tag">(0, 1, 0)</span> gives us a vector pointing
            sideways along the ground &mdash; exactly the direction we need to
            widen the edge.
          </p>
          <p>
            <strong>3.</strong> Offset each endpoint: push
            <span class="tag">v0</span> and <span class="tag">v1</span> both
            left (<span class="tag">- right * half</span>) and right (<span
              class="tag"
              >+ right * half</span
            >) to create 4 corners of a thin rectangle.
            <span class="tag">half</span> is half the desired line thickness
            (2.5 mm per side = 5 mm total).
          </p>
          <p>
            <strong>4.</strong> Two triangles make the quad: indices
            <span class="tag">[0,1,2]</span> and
            <span class="tag">[0,2,3]</span> fill the rectangle. Repeat for
            every edge around the boundary.
          </p>
          <p>
            Finally, pack all positions, normals, and indices into a
            <span class="tag">MeshDescriptor</span> and generate a
            <span class="tag">MeshResource</span>. A translucent white
            <span class="tag">UnlitMaterial</span> keeps the outline clean.
          </p>
        </div>
        <div class="expl" data-hl="30-38">
          <div class="expl-label">Update</div>
          <h3>Create or update the outline entity</h3>
          <p>
            Track outline entities by plane <span class="tag">UUID</span>. When
            a plane updates, swap the mesh on the existing entity. When a new
            plane appears, create an <span class="tag">AnchorEntity</span> and
            add the outline as a child. Set its transform from
            <span class="tag">planeAnchor.transform</span> so it sits in world
            space.
          </p>
        </div>
      </div>
      <div class="code-panel">
        <div class="code-bar">
          <div class="dots"><span></span><span></span><span></span></div>
          <div class="code-fname">PlaneOutlines.swift</div>
        </div>
        <div class="code-scroll" id="code-outline"></div>
      </div>
    </div>

    <!-- ====== 19 HAND PINCH ====== -->
    <div class="section" data-section="handpinch">
      <div class="explain-panel">
        <div class="divider" id="s-handpinch">
          <div class="num">19 — HAND PINCH</div>
          <h2>Vision Hand Tracking</h2>
          <p>
            Use the Vision framework to detect hand poses in camera frames and
            build a pinch-to-grab interaction for moving AR entities.
          </p>
        </div>
        <div class="expl" data-hl="1-5">
          <div class="expl-label">Setup</div>
          <h3>Create a hand pose request</h3>
          <p>
            <span class="tag">VNDetectHumanHandPoseRequest</span> detects up to
            2 hands per frame. Store it on your coordinator and set
            <span class="tag">maximumHandCount</span> to limit processing.
          </p>
          <div class="note">
            Hand pose detection runs on the CPU via Vision — no special hardware
            required beyond the front camera. Works alongside ARKit world
            tracking.
          </div>
        </div>
        <div class="expl" data-hl="7-17">
          <div class="expl-label">Detect</div>
          <h3>Process each AR frame</h3>
          <p>
            In <span class="tag">session(_:didUpdate:)</span>, grab the
            <span class="tag">capturedImage</span> pixel buffer from the frame
            and run the hand pose request through a
            <span class="tag">VNImageRequestHandler</span>.
          </p>
          <p>
            The <span class="tag">.right</span> orientation corrects for the
            camera sensor's native landscape orientation so landmark coordinates
            map correctly to the portrait screen.
          </p>
        </div>
        <div class="expl" data-hl="19-33">
          <div class="expl-label">Pinch</div>
          <h3>Detect thumb-index pinch</h3>
          <p>
            Read <span class="tag">.thumbTip</span> and
            <span class="tag">.indexTip</span> landmarks. If both have
            sufficient confidence, compute their Euclidean distance — below a
            threshold (≈ 0.05 in normalised coords) means pinching.
          </p>
          <p>
            The midpoint between the two fingertips gives a stable screen
            position for the grab point. Convert from Vision's bottom-left
            origin to UIKit's top-left origin with
            <span class="tag">1 − y</span>.
          </p>
        </div>
        <div class="expl" data-hl="35-53">
          <div class="expl-label">Grab</div>
          <h3>Pinch-to-drag an entity</h3>
          <p>
            Track pinch state transitions: on <strong>pinch start</strong>,
            hit-test the screen point with
            <span class="tag">arView.entity(at:)</span> and switch the body to
            <span class="tag">.kinematic</span> so physics won't fight you.
          </p>
          <p>
            While <strong>pinch continues</strong>, cast a ray through the
            updated screen point and position the entity at the same distance
            from the camera. On <strong>release</strong>, flip back to
            <span class="tag">.dynamic</span> so it drops naturally.
          </p>
        </div>
      </div>
      <div class="code-panel">
        <div class="code-bar">
          <div class="dots"><span></span><span></span><span></span></div>
          <div class="code-fname">HandPinch.swift</div>
        </div>
        <div class="code-scroll" id="code-handpinch"></div>
      </div>
    </div>

    <!-- ====== 20 USDZ ANIMATIONS ====== -->
    <div class="section" data-section="usdzanim">
      <div class="explain-panel">
        <div class="divider" id="s-usdzanim">
          <div class="num">20 — USDZ ANIMATIONS</div>
          <h2>Playing Animations from USDZ</h2>
          <p>
            USDZ files can contain embedded skeletal or transform animations.
            Here&rsquo;s how to load, list, and play them.
          </p>
        </div>
        <div class="expl" data-hl="1-4">
          <div class="expl-label">Load</div>
          <h3>Load the animated model</h3>
          <p>
            Use <span class="tag">Entity.loadAsync(named:)</span> or
            <span class="tag">try await Entity(named:)</span> to load a
            <span class="tag">.usdz</span> that contains embedded animations.
            The animations are stored as
            <span class="tag">AnimationResource</span> objects on the entity.
          </p>
        </div>
        <div class="expl" data-hl="6-11">
          <div class="expl-label">Discover</div>
          <h3>List available animations</h3>
          <p>
            Access <span class="tag">entity.availableAnimations</span> to get an
            array of <span class="tag">AnimationResource</span> objects baked
            into the USDZ file. Each one represents a distinct animation clip
            (walk, idle, wave, etc.).
          </p>
          <p>
            The <span class="tag">name</span> property on each resource tells
            you what the animation is called, as authored in the 3D tool.
          </p>
        </div>
        <div class="expl" data-hl="13-16">
          <div class="expl-label">Play</div>
          <h3>Play the first animation</h3>
          <p>
            Call <span class="tag">entity.playAnimation(_:)</span> with an
            <span class="tag">AnimationResource</span> to start playback. Pass
            <span class="tag">transitionDuration:</span> for a smooth blend from
            the current pose. Set <span class="tag">startsPaused: true</span> to
            load without auto-playing.
          </p>
          <div class="note">
            The returned <span class="tag">AnimationPlaybackController</span>
            lets you pause, resume, stop, and adjust speed at any time.
          </div>
        </div>
        <div class="expl" data-hl="18-24">
          <div class="expl-label">Control</div>
          <h3>Pause, resume &amp; adjust speed</h3>
          <p>
            The <span class="tag">AnimationPlaybackController</span> returned by
            <span class="tag">playAnimation</span> gives full control:
            <span class="tag">.pause()</span>,
            <span class="tag">.resume()</span>,
            <span class="tag">.stop()</span>, and
            <span class="tag">.speed</span> (set to
            <span class="tag">2.0</span> for double speed,
            <span class="tag">-1.0</span> for reverse).
          </p>
        </div>
        <div class="expl" data-hl="26-31">
          <div class="expl-label">Repeat</div>
          <h3>Looping &amp; repeating</h3>
          <p>
            Wrap an animation in
            <span class="tag">.repeat()</span> to loop it forever, or
            <span class="tag">.repeat(count:)</span> for a fixed number of
            cycles. You can also set <span class="tag">trimStart</span> /
            <span class="tag">trimEnd</span> /
            <span class="tag">trimDuration</span>
            to play just a portion of the clip.
          </p>
        </div>
        <div class="expl" data-hl="33-42">
          <div class="expl-label">Blend</div>
          <h3>Blending &amp; sequencing animations</h3>
          <p>
            Use <span class="tag">AnimationResource.sequence(with:)</span> to
            chain two animations back-to-back, or
            <span class="tag">AnimationGroup</span> to play multiple animations
            simultaneously. Combine with
            <span class="tag">transitionDuration</span> for smooth crossfades
            between clips.
          </p>
        </div>
      </div>
      <div class="code-panel">
        <div class="code-bar">
          <div class="dots"><span></span><span></span><span></span></div>
          <div class="code-fname">USDZAnimations.swift</div>
        </div>
        <div class="code-scroll" id="code-usdzanim"></div>
      </div>
    </div>

    <!-- ====== 21 MESH PLANE CROSSING ====== -->
    <div class="section" data-section="meshcross">
      <div class="explain-panel">
        <div class="divider" id="s-meshcross">
          <div class="num">21 — MESH PLANE CROSSING</div>
          <h2>Detecting Objects Crossing a Virtual Plane</h2>
          <p>
            Use the LiDAR mesh vertices to detect when a real-world object (a
            hand, a pet, a ball) crosses an invisible vertical plane 1 m in
            front of the camera.
          </p>
        </div>
        <div class="expl" data-hl="1-5">
          <div class="expl-label">Concept</div>
          <h3>What is a virtual plane?</h3>
          <p>
            A plane in 3D can be defined by a point on it and a
            <strong>normal</strong> — a direction pointing straight out of the
            surface. For a vertical wall 1 m ahead, the point is
            <span class="tag">(0, 0, &ndash;1)</span> and the normal points back
            toward the camera: <span class="tag">(0, 0, 1)</span>.
          </p>
          <p>
            To test if a mesh vertex is &ldquo;past&rdquo; this plane, take the
            <strong>dot product</strong> of
            <span class="tag">(vertex &ndash; planePoint)</span> with the
            normal. If the result is negative, the vertex is on the far side of
            the plane (farther than 1 m away).
          </p>
          <div class="note">
            The <strong>dot product</strong> is a single number that tells you
            how much one vector points in the same direction as another.
            Positive = same side as the normal. Negative = opposite side. Zero =
            exactly on the plane.
          </div>
        </div>
        <div class="expl" data-hl="7-14">
          <div class="expl-label">Setup</div>
          <h3>Define the plane once at startup</h3>
          <p>
            Capture the camera position and forward direction when the session
            starts. Move 1 m ahead to get the plane&rsquo;s anchor point. The
            normal faces back toward the camera so that anything farther away
            produces a negative dot product.
          </p>
          <p>
            <span class="tag">cam.columns.2</span> is the
            <strong>third column</strong> of the 4&times;4 transform matrix. In
            a column-major transform, column&nbsp;0 = right (X), column&nbsp;1 =
            up (Y), column&nbsp;2 = forward (Z), and column&nbsp;3 = position.
            Extracting <span class="tag">.x</span>, <span class="tag">.y</span>,
            <span class="tag">.z</span> and packing them into a
            <span class="tag">SIMD3&lt;Float&gt;</span> gives you the
            camera&rsquo;s forward direction as a 3D vector (dropping the
            <span class="tag">.w</span> component).
          </p>
          <div class="note">
            In ARKit the camera looks down <strong>&ndash;Z</strong>, so
            <span class="tag">columns.2</span> actually points
            <em>behind</em> you. That&rsquo;s why we
            <strong>subtract</strong> it from position to get a point 1&nbsp;m
            <em>ahead</em>.
          </div>
          <p>
            Store <span class="tag">planePoint</span> and
            <span class="tag">planeNormal</span> as
            <span class="tag">SIMD3&lt;Float&gt;</span> properties on your
            coordinator.
          </p>
        </div>
        <div class="expl" data-hl="16-31">
          <div class="expl-label">Check</div>
          <h3>Test every mesh vertex each frame</h3>
          <p>
            In <span class="tag">didUpdate anchors</span>, loop through each
            <span class="tag">ARMeshAnchor</span>. For every vertex, transform
            it to world space (multiply by the mesh anchor&rsquo;s transform),
            then compute
            <span class="tag">dot(vertex &ndash; planePoint, normal)</span>.
          </p>
          <p>
            If the dot product is <strong>&lt; 0</strong>, that vertex has
            crossed the plane. Count them — if enough vertices cross (e.g. 10+),
            something real has moved past your invisible wall.
          </p>
        </div>
        <div class="expl" data-hl="33-37">
          <div class="expl-label">React</div>
          <h3>Trigger an event</h3>
          <p>
            Once the crossing count exceeds a threshold, fire your event — play
            a sound, show a visual effect, or send a notification. Reset a
            cooldown timer to avoid retriggering every frame.
          </p>
          <div class="note">
            This technique works for any invisible boundary — doorways, safety
            zones, game triggers. Just change the plane point and normal to
            define any flat boundary in space.
          </div>
        </div>
      </div>
      <div class="code-panel">
        <div class="code-bar">
          <div class="dots"><span></span><span></span><span></span></div>
          <div class="code-fname">MeshPlaneCrossing.swift</div>
        </div>
        <div class="code-scroll" id="code-meshcross"></div>
      </div>
    </div>

    <footer>
      ARKit & RealityKit with LiDAR — Interactive Guide · Swift · iOS 17+
    </footer>

    <script>
      function k(s) {
        return { t: s, c: 'kw' };
      }
      function t(s) {
        return { t: s, c: '' };
      }
      function tp(s) {
        return { t: s, c: 'tp' };
      }
      function fn(s) {
        return { t: s, c: 'fn' };
      }
      function st(s) {
        return { t: s, c: 'st' };
      }
      function cm(s) {
        return { t: s, c: 'cm' };
      }
      function pr(s) {
        return { t: s, c: 'pr' };
      }
      function nm(s) {
        return { t: s, c: 'nm' };
      }
      function en(s) {
        return { t: s, c: 'en' };
      }
      function pm(s) {
        return { t: s, c: 'pm' };
      }
      const C = {
        setup: [
          [k('import'), t(' SwiftUI')],
          [k('import'), t(' RealityKit')],
          [k('import'), t(' ARKit')],
          [],
          [
            k('struct'),
            t(' '),
            tp('ARViewContainer'),
            t(': '),
            tp('UIViewRepresentable'),
            t(' {'),
          ],
          [
            t('    '),
            k('func'),
            t(' '),
            fn('makeUIView'),
            t('('),
            pm('context'),
            t(': '),
            tp('Context'),
            t(') -> '),
            tp('ARView'),
            t(' {'),
          ],
          [
            t('        '),
            k('let'),
            t(' arView = '),
            tp('ARView'),
            t('('),
            pm('frame'),
            t(': .zero)'),
          ],
          [
            t('        '),
            k('let'),
            t(' config = '),
            tp('ARWorldTrackingConfiguration'),
            t('()'),
          ],
          [],
          [t('        '), cm('// LiDAR features')],
          [
            t('        config.'),
            pr('sceneReconstruction'),
            t(' = .'),
            en('meshWithClassification'),
          ],
          [
            t('        config.'),
            pr('planeDetection'),
            t(' = [.'),
            en('horizontal'),
            t(', .'),
            en('vertical'),
            t(']'),
          ],
          [
            t('        config.'),
            pr('environmentTexturing'),
            t(' = .'),
            en('automatic'),
          ],
          [
            t('        config.'),
            pr('frameSemantics'),
            t(' = [.'),
            en('sceneDepth'),
            t(', .'),
            en('smoothedSceneDepth'),
            t(']'),
          ],
          [],
          [
            t('        arView.'),
            pr('session'),
            t('.'),
            fn('run'),
            t('(config)'),
          ],
          [
            t('        arView.'),
            pr('session'),
            t('.'),
            pr('delegate'),
            t(' = context.'),
            pr('coordinator'),
          ],
          [],
          [t('        '), cm('// Coaching overlay — "move your phone around"')],
          [
            t('        '),
            k('let'),
            t(' coaching = '),
            tp('ARCoachingOverlayView'),
            t('()'),
          ],
          [
            t('        coaching.'),
            pr('session'),
            t(' = arView.'),
            pr('session'),
          ],
          [
            t('        coaching.'),
            pr('goal'),
            t(' = .'),
            en('horizontalPlane'),
          ],
          [
            t('        coaching.'),
            pr('activatesAutomatically'),
            t(' = '),
            k('true'),
          ],
          [t('        arView.'), fn('addSubview'), t('(coaching)')],
          [],
          [t('        '), k('return'), t(' arView')],
          [t('    }')],
          [],
          [t('    '), cm('// Coordinator acts as the ARSessionDelegate')],
          [
            t('    '),
            k('func'),
            t(' '),
            fn('makeCoordinator'),
            t('() -> '),
            tp('Coordinator'),
            t(' { '),
            tp('Coordinator'),
            t('() }'),
          ],
          [],
          [
            t('    '),
            k('class'),
            t(' '),
            tp('Coordinator'),
            t(': '),
            tp('NSObject'),
            t(', '),
            tp('ARSessionDelegate'),
            t(' {'),
          ],
          [
            t('        '),
            k('func'),
            t(' '),
            fn('session'),
            t('('),
            k('_'),
            t(' session: '),
            tp('ARSession'),
            t(', '),
            pm('didUpdate'),
            t(' frame: '),
            tp('ARFrame'),
            t(') {'),
          ],
          [
            t('            '),
            cm('// Called ~60× per second — AR logic goes here'),
          ],
          [t('        }')],
          [
            t('        '),
            k('func'),
            t(' '),
            fn('session'),
            t('('),
            k('_'),
            t(' session: '),
            tp('ARSession'),
            t(', '),
            pm('didAdd'),
            t(' anchors: ['),
            tp('ARAnchor'),
            t(']) { }'),
          ],
          [t('    }')],
          [
            t('    '),
            k('func'),
            t(' '),
            fn('updateUIView'),
            t('('),
            k('_'),
            t(' uiView: '),
            tp('ARView'),
            t(', '),
            pm('context'),
            t(': '),
            tp('Context'),
            t(') {}'),
          ],
          [t('}')],
        ],
        types: [
          [cm('// ── ARView ──────────────────────────────────')],
          [
            k('let'),
            t(' arView = '),
            tp('ARView'),
            t('('),
            pm('frame'),
            t(': .zero)'),
          ],
          [t('arView.'), pr('session'), t('         '), cm('// ARSession')],
          [
            t('arView.'),
            pr('scene'),
            t('           '),
            cm('// Scene — root of entity tree'),
          ],
          [
            t('arView.'),
            pr('cameraTransform'),
            t(' '),
            cm('// Transform — device pose'),
          ],
          [
            t('arView.'),
            fn('raycast'),
            t('('),
            pm('from'),
            t(':,'),
            pm('allowing'),
            t(':,'),
            pm('alignment'),
            t(':)'),
          ],
          [
            t('arView.'),
            fn('entity'),
            t('('),
            pm('at'),
            t(': point)  '),
            cm('// hit-test virtual objects'),
          ],
          [
            t('arView.'),
            fn('installGestures'),
            t('(.'),
            en('all'),
            t(', '),
            pm('for'),
            t(': model)'),
          ],
          [
            t('arView.'),
            pr('debugOptions'),
            t('     '),
            cm('// show mesh, origin, etc.'),
          ],
          [],
          [cm('// ── ARSession ────────────────────────────────')],
          [k('let'), t(' session = arView.'), pr('session')],
          [
            t('session.'),
            fn('run'),
            t('(config)       '),
            cm('// start tracking'),
          ],
          [
            t('session.'),
            fn('pause'),
            t('()            '),
            cm('// suspend tracking'),
          ],
          [
            t('session.'),
            pr('delegate'),
            t('          '),
            cm('// ARSessionDelegate'),
          ],
          [
            t('session.'),
            pr('currentFrame'),
            t('      '),
            cm('// ARFrame? — latest snapshot'),
          ],
          [
            t('session.'),
            fn('raycast'),
            t('(query)    '),
            cm('// [ARRaycastResult]'),
          ],
          [
            t('session.'),
            fn('trackedRaycast'),
            t('(q) { results '),
            k('in'),
            t(' } '),
            cm('// refines over time'),
          ],
          [
            t('session.'),
            fn('add'),
            t('('),
            pm('anchor'),
            t(': myAnchor) '),
            cm('// manually add an ARAnchor'),
          ],
          [],
          [cm('// ── ARFrame (delivered ~60×/sec) ─────────────')],
          [k('let'), t(' frame: '), tp('ARFrame')],
          [t('frame.'), pr('camera'), t('             '), cm('// ARCamera')],
          [
            t('frame.camera.'),
            pr('transform'),
            t('    '),
            cm('// simd_float4x4 — pose'),
          ],
          [
            t('frame.camera.'),
            pr('intrinsics'),
            t('   '),
            cm('// simd_float3x3 — focal length'),
          ],
          [
            t('frame.camera.'),
            pr('projectionMatrix'),
            cm('// simd_float4x4 — 3D→2D'),
          ],
          [
            t('frame.'),
            pr('capturedImage'),
            t('      '),
            cm('// CVPixelBuffer — camera image'),
          ],
          [
            t('frame.'),
            pr('sceneDepth'),
            t('         '),
            cm('// ARDepthData? — LiDAR depth'),
          ],
          [
            t('frame.'),
            pr('smoothedSceneDepth'),
            t(' '),
            cm('// ARDepthData? — filtered'),
          ],
          [
            t('frame.'),
            pr('anchors'),
            t('            '),
            cm('// [ARAnchor] — all current anchors'),
          ],
          [
            t('frame.'),
            pr('lightEstimate'),
            t('      '),
            cm('// ARLightEstimate?'),
          ],
          [
            t('frame.'),
            pr('timestamp'),
            t('          '),
            cm('// TimeInterval'),
          ],
          [],
          [cm('// ── ARAnchor subclasses ──────────────────────')],
          [k('let'), t(' anchor: '), tp('ARAnchor')],
          [t('anchor.'), pr('identifier'), t('  '), cm('// UUID')],
          [
            t('anchor.'),
            pr('transform'),
            t('   '),
            cm('// simd_float4x4 — world pose'),
          ],
          [],
          [cm('// ARPlaneAnchor — detected surface')],
          [
            t('plane.'),
            pr('alignment'),
            t('   '),
            cm('// .horizontal | .vertical'),
          ],
          [
            t('plane.'),
            pr('center'),
            t('      '),
            cm('// simd_float3 — center in local space'),
          ],
          [
            t('plane.'),
            pr('extent'),
            t('      '),
            cm('// simd_float3 — width/height of plane'),
          ],
          [
            t('plane.'),
            pr('classification'),
            cm('// .floor .wall .table .seat .door …'),
          ],
          [],
          [cm('// ── Entity hierarchy (RealityKit) ────────────')],
          [k('let'), t(' entity: '), tp('Entity')],
          [
            t('entity.'),
            pr('transform'),
            t('       '),
            cm('// Transform (position, rotation, scale)'),
          ],
          [
            t('entity.'),
            fn('position'),
            t('('),
            pm('relativeTo'),
            t(': '),
            k('nil'),
            t(') '),
            cm('// world space'),
          ],
          [
            t('entity.'),
            fn('setPosition'),
            t('(pos, '),
            pm('relativeTo'),
            t(': '),
            k('nil'),
            t(')'),
          ],
          [
            t('entity.'),
            pr('children'),
            t('        '),
            cm('// Entity.ChildCollection'),
          ],
          [t('entity.'), fn('addChild'), t('(other)')],
          [],
          [cm('// ModelEntity — adds mesh + materials')],
          [
            t('model.'),
            pr('model'),
            t('?.'),
            pr('mesh'),
            t('     '),
            cm('// MeshResource'),
          ],
          [
            t('model.'),
            pr('model'),
            t('?.'),
            pr('materials'),
            t(' '),
            cm('// [Material]'),
          ],
          [
            t('model.'),
            fn('generateCollisionShapes'),
            t('('),
            pm('recursive'),
            t(': '),
            k('true'),
            t(')'),
          ],
          [
            t('model.'),
            pr('collision'),
            t('        '),
            cm('// CollisionComponent?'),
          ],
          [
            t('model.'),
            pr('physicsBody'),
            t('      '),
            cm('// PhysicsBodyComponent?'),
          ],
        ],
        anchors: [
          [cm('// 1. Ground plane via delegate (Coordinator)')],
          [
            k('func'),
            t(' '),
            fn('session'),
            t('('),
            k('_'),
            t(' s: '),
            tp('ARSession'),
            t(', '),
            pm('didAdd'),
            t(' anchors: ['),
            tp('ARAnchor'),
            t(']) {'),
          ],
          [t('    '), k('for'), t(' anchor '), k('in'), t(' anchors {')],
          [
            t('        '),
            k('guard let'),
            t(' plane = anchor '),
            k('as'),
            t('? '),
            tp('ARPlaneAnchor'),
            t(','),
          ],
          [
            t('              plane.'),
            pr('classification'),
            t(' == .'),
            en('floor'),
          ],
          [t('        '), k('else'), t(' { '), k('continue'), t(' }')],
          [
            t('        '),
            k('let'),
            t(' entity = '),
            tp('AnchorEntity'),
            t('('),
            pm('anchor'),
            t(': plane)'),
          ],
          [t('        '), cm('// add child models to entity...')],
          [t('        arView.scene.'), fn('addAnchor'), t('(entity)')],
          [t('    }')],
          [t('}')],
          [],
          [cm('// 2. Convenience — auto-places on detected surfaces')],
          [
            tp('AnchorEntity'),
            t('('),
            pm('plane'),
            t(': .'),
            en('horizontal'),
            t(')'),
          ],
          [
            tp('AnchorEntity'),
            t('('),
            pm('plane'),
            t(': .'),
            en('horizontal'),
            t(', '),
            pm('classification'),
            t(': .'),
            en('floor'),
            t(')'),
          ],
          [
            tp('AnchorEntity'),
            t('('),
            pm('plane'),
            t(': .'),
            en('horizontal'),
            t(', '),
            pm('classification'),
            t(': .'),
            en('table'),
            t(')'),
          ],
          [
            tp('AnchorEntity'),
            t('('),
            pm('plane'),
            t(': .'),
            en('vertical'),
            t(')'),
          ],
          [],
          [cm('// 3. World position — fixed in 3D space')],
          [
            tp('AnchorEntity'),
            t('('),
            pm('world'),
            t(': '),
            tp('simd_float3'),
            t('('),
            nm('0'),
            t(', '),
            nm('0'),
            t(', -'),
            nm('1'),
            t('))'),
          ],
          [],
          [cm('// 4. From a raycast result')],
          [tp('AnchorEntity'), t('('), pm('raycastResult'), t(': result)')],
          [],
          [cm('// 5. Camera-relative (follows device)')],
          [tp('AnchorEntity'), t('(.'), en('camera'), t(')')],
          [],
          [cm('// 6. Image tracking')],
          [tp('AnchorEntity'), t('(.'), en('image'), t('(')],
          [
            t('    '),
            pm('group'),
            t(': '),
            st('"AR Resources"'),
            t(', '),
            pm('name'),
            t(': '),
            st('"poster"'),
            t('))'),
          ],
          [],
          [cm('// 7. Body tracking')],
          [tp('AnchorEntity'), t('(.'), en('body'), t(')')],
          [],
          [cm('// Requires ARBodyTrackingConfiguration')],
          [
            k('let'),
            t(' bodyConfig = '),
            tp('ARBodyTrackingConfiguration'),
            t('()'),
          ],
          [t('bodyConfig.'), pr('planeDetection'), t(' = .'), en('horizontal')],
          [t('arView.'), pr('session'), t('.'), fn('run'), t('(bodyConfig)')],
          [],
          [cm('// Access skeleton joints from ARBodyAnchor')],
          [
            k('func'),
            t(' '),
            fn('session'),
            t('('),
            k('_'),
            t(' s: '),
            tp('ARSession'),
            t(', '),
            pm('didUpdate'),
            t(' anchors: ['),
            tp('ARAnchor'),
            t(']) {'),
          ],
          [
            t('    '),
            k('guard let'),
            t(' body = anchors.'),
            pr('first'),
            t(' '),
            k('as'),
            t('? '),
            tp('ARBodyAnchor'),
          ],
          [t('    '), k('else'), t(' { '), k('return'), t(' }')],
          [
            t('    '),
            k('let'),
            t(' skeleton = body.'),
            pr('skeleton'),
            t(' '),
            cm('// ARSkeleton3D'),
          ],
          [
            t('    '),
            k('let'),
            t(' def = '),
            tp('ARSkeletonDefinition'),
            t('.'),
            pr('defaultBody3D'),
          ],
          [
            t('    '),
            k('if let'),
            t(' idx = def.'),
            fn('index'),
            t('('),
            pm('for'),
            t(': .'),
            en('head'),
            t(') {'),
          ],
          [
            t('        '),
            k('let'),
            t(' jointT = skeleton.'),
            pr('jointLocalTransforms'),
            t('[idx]'),
          ],
          [
            t('        '),
            k('let'),
            t(' worldT = body.'),
            pr('transform'),
            t(' * jointT'),
          ],
          [t('    }')],
          [t('}')],
        ],
        depthbuf: [
          [cm('// Get the depth buffer from the current frame')],
          [
            k('guard let'),
            t(' frame = arView.'),
            pr('session'),
            t('.'),
            pr('currentFrame'),
            t(','),
          ],
          [
            t('      '),
            k('let'),
            t(' depth = frame.'),
            pr('sceneDepth'),
            t(' '),
            cm('// ARDepthData?'),
          ],
          [t('      '), k('else'), t(' { '), k('return'), t(' }')],
          [
            k('let'),
            t(' depthMap = depth.'),
            pr('depthMap'),
            t(' '),
            cm('// CVPixelBuffer'),
          ],
          [],
          [cm('// Lock the pixel buffer for CPU access')],
          [
            tp('CVPixelBufferLockBaseAddress'),
            t('(depthMap, .'),
            en('readOnly'),
            t(')'),
          ],
          [
            k('defer'),
            t(' { '),
            tp('CVPixelBufferUnlockBaseAddress'),
            t('(depthMap, .'),
            en('readOnly'),
            t(') }'),
          ],
          [],
          [
            k('let'),
            t(' w = '),
            tp('CVPixelBufferGetWidth'),
            t('(depthMap)  '),
            cm('// Int, typically 256'),
          ],
          [
            k('let'),
            t(' h = '),
            tp('CVPixelBufferGetHeight'),
            t('(depthMap) '),
            cm('// Int, typically 192'),
          ],
          [],
          [cm('// Bind as Float32 array')],
          [
            k('let'),
            t(' base = '),
            tp('CVPixelBufferGetBaseAddress'),
            t('(depthMap)!'),
          ],
          [k('let'), t(' floats = base.'), fn('assumingMemoryBound'), t('(')],
          [t('    '), pm('to'), t(': '), tp('Float32'), t('.self)')],
          [],
          [cm('// Read center pixel depth (meters)')],
          [
            k('let'),
            t(' centerDepth = floats[h/'),
            nm('2'),
            t(' * w + w/'),
            nm('2'),
            t('] '),
            cm('// Float32'),
          ],
          [],
          [cm('// Unproject a depth pixel to 3D world point')],
          [
            k('let'),
            t(' intrinsics = frame.camera.'),
            pr('intrinsics'),
            t(' '),
            cm('// simd_float3x3'),
          ],
          [
            k('let'),
            t(' fx = intrinsics['),
            nm('0'),
            t(']['),
            nm('0'),
            t('], fy = intrinsics['),
            nm('1'),
            t(']['),
            nm('1'),
            t(']'),
          ],
          [
            k('let'),
            t(' cx = intrinsics['),
            nm('2'),
            t(']['),
            nm('0'),
            t('], cy = intrinsics['),
            nm('2'),
            t(']['),
            nm('1'),
            t(']'),
          ],
          [
            k('let'),
            t(' x = ('),
            tp('Float'),
            t('(px) - cx) * centerDepth / fx'),
          ],
          [
            k('let'),
            t(' y = ('),
            tp('Float'),
            t('(py) - cy) * centerDepth / fy'),
          ],
          [
            k('let'),
            t(' localPt = '),
            tp('simd_float4'),
            t('(x, y, centerDepth, '),
            nm('1'),
            t(')'),
          ],
          [
            k('let'),
            t(' worldPt = frame.camera.'),
            pr('viewMatrix'),
            t('('),
            pm('for'),
            t(': .'),
            en('landscapeRight'),
            t(')'),
          ],
          [t('    * localPt '), cm('// simd_float4 in world space')],
        ],
        coordinates: [
          [cm('// ARKit: Right-handed coordinate system, units in meters')],
          [cm('//   +Y (up)  |  +X (right)  |  +Z (toward user)')],
          [cm('//   Camera initially looks down -Z')],
          [cm('//   Origin = device position at session start')],
          [],
          [
            k('let'),
            t(' transform: '),
            tp('simd_float4x4'),
            t(' = entity.transform.matrix'),
          ],
          [k('let'), t(' position = '), tp('simd_float3'), t('(')],
          [t('    transform.columns.'), nm('3'), t('.x,')],
          [t('    transform.columns.'), nm('3'), t('.y,')],
          [t('    transform.columns.'), nm('3'), t('.z')],
          [t(')')],
          [],
          [k('let'), t(' camera = frame.'), pr('camera')],
          [
            t('camera.'),
            pr('transform'),
            t('        '),
            cm('// simd_float4x4 — pose in world space'),
          ],
          [
            t('camera.'),
            pr('eulerAngles'),
            t('      '),
            cm('// simd_float3 — pitch, yaw, roll'),
          ],
          [
            t('camera.'),
            pr('intrinsics'),
            t('       '),
            cm('// simd_float3x3 — focal length'),
          ],
          [
            t('camera.'),
            pr('projectionMatrix'),
            t(' '),
            cm('// simd_float4x4 — 3D to 2D'),
          ],
          [],
          [cm('// Project a 3D world point onto the screen')],
          [
            k('let'),
            t(' view = camera.'),
            fn('viewMatrix'),
            t('('),
            pm('for'),
            t(': .'),
            en('landscapeRight'),
            t(')'),
          ],
          [k('let'), t(' proj = camera.'), pr('projectionMatrix')],
          [
            k('let'),
            t(' clip = proj * view * '),
            tp('simd_float4'),
            t('(worldPt, '),
            nm('1'),
            t(')'),
          ],
          [k('let'), t(' ndc  = clip / clip.w '), cm('// perspective divide')],
          [
            k('let'),
            t(' screenX = (ndc.x + '),
            nm('1'),
            t(') * '),
            nm('0.5'),
            t(' * '),
            tp('Float'),
            t('(screenW)'),
          ],
          [
            k('let'),
            t(' screenY = ('),
            nm('1'),
            t(' - ndc.y) * '),
            nm('0.5'),
            t(' * '),
            tp('Float'),
            t('(screenH)'),
          ],
        ],
        spawning: [
          [cm('// camera.transform is a simd_float4x4 — a 4×4 matrix:')],
          [cm('//   columns.0 = right   (local +X axis)')],
          [cm('//   columns.1 = up      (local +Y axis)')],
          [cm('//   columns.2 = forward (local +Z — camera looks –Z)')],
          [cm('//   columns.3 = position (x, y, z, 1)')],
          [cm('// Each column is a simd_float4 (x, y, z, w).')],
          [],
          [
            k('let'),
            t(' cam = arView.'),
            pr('session'),
            t('.'),
            pr('currentFrame'),
            t('!.'),
            pr('camera'),
            t('.'),
            pr('transform'),
          ],
          [],
          [cm('// Column 2 points where +Z faces. Camera looks –Z,')],
          [cm('// so subtracting it moves 1 m AHEAD of the camera.')],
          [k('let'), t(' fwd = cam.columns.'), nm('2')],
          [k('let'), t(' pos = cam.columns.'), nm('3')],
          [cm('// Extract xyz from the simd_float4 columns:')],
          [
            k('let'),
            t(' ahead = '),
            tp('SIMD3'),
            t('<'),
            tp('Float'),
            t('>(pos.x - fwd.x, pos.y - fwd.y, pos.z - fwd.z)'),
          ],
          [],
          [cm('// Raycast straight down to find the floor')],
          [k('let'), t(' query = '), tp('ARRaycastQuery'), t('(')],
          [t('    '), pm('origin'), t(': ahead,')],
          [
            t('    '),
            pm('direction'),
            t(': ['),
            nm('0'),
            t(', -'),
            nm('1'),
            t(', '),
            nm('0'),
            t('],'),
          ],
          [t('    '), pm('allowing'), t(': .'), en('estimatedPlane'), t(',')],
          [t('    '), pm('alignment'), t(': .'), en('horizontal')],
          [t(')')],
          [
            k('guard let'),
            t(' hit = arView.'),
            pr('session'),
            t('.'),
            fn('raycast'),
            t('(query).'),
            pr('first'),
            t(' '),
            k('else'),
            t(' { '),
            k('return'),
            t(' }'),
          ],
          [],
          [cm('// Place a model where the ray hit the floor')],
          [
            k('let'),
            t(' char = '),
            k('try'),
            t(' '),
            k('await'),
            t(' '),
            tp('ModelEntity'),
            t('('),
            pm('named'),
            t(': '),
            st('"character"'),
            t(')'),
          ],
          [
            k('var'),
            t(' xform = '),
            tp('float4x4'),
            t('('),
            nm('1'),
            t(') '),
            cm('// identity'),
          ],
          [
            t('xform.columns.'),
            nm('3'),
            t(' = hit.'),
            pr('worldTransform'),
            t('.columns.'),
            nm('3'),
            t(' '),
            cm('// floor position'),
          ],
          [
            k('let'),
            t(' anchor = '),
            tp('AnchorEntity'),
            t('('),
            pm('world'),
            t(': xform)'),
          ],
          [t('anchor.'), fn('addChild'), t('(char)')],
          [t('arView.scene.'), fn('addAnchor'), t('(anchor)')],
          [
            t('char.'),
            fn('generateCollisionShapes'),
            t('('),
            pm('recursive'),
            t(': '),
            k('true'),
            t(')'),
          ],
        ],
        kinematic: [
          [
            k('func'),
            t(' '),
            fn('session'),
            t('('),
            k('_'),
            t(' s: '),
            tp('ARSession'),
            t(', '),
            pm('didUpdate'),
            t(' frame: '),
            tp('ARFrame'),
            t(') {'),
          ],
          [
            t('    '),
            k('let'),
            t(' dt = '),
            tp('Float'),
            t('(frame.'),
            pr('timestamp'),
            t(' - lastTime)'),
          ],
          [
            t('    '),
            k('let'),
            t(' dir = '),
            fn('normalize'),
            t('(waypointPos - char.'),
            pr('position'),
            t(')'),
          ],
          [t('    char.'), pr('position'), t(' += dir * speed * dt')],
          [t('    lastTime = frame.'), pr('timestamp')],
          [t('}')],
        ],
        joystick: [
          [cm('// Extract camera forward projected onto XZ plane')],
          [k('let'), t(' camTransform = arView.'), pr('cameraTransform')],
          [
            k('let'),
            t(' camFwd = camTransform.'),
            pr('matrix'),
            t('.columns.'),
            nm('2'),
          ],
          [
            k('var'),
            t(' forward = '),
            tp('SIMD3'),
            t('<'),
            tp('Float'),
            t('>(-camFwd.x, '),
            nm('0'),
            t(', -camFwd.z)'),
          ],
          [t('forward = '), fn('simd_normalize'), t('(forward)')],
          [],
          [cm('// Camera right projected onto XZ plane')],
          [
            k('let'),
            t(' camRight = camTransform.'),
            pr('matrix'),
            t('.columns.'),
            nm('0'),
          ],
          [
            k('var'),
            t(' right = '),
            tp('SIMD3'),
            t('<'),
            tp('Float'),
            t('>(camRight.x, '),
            nm('0'),
            t(', camRight.z)'),
          ],
          [t('right = '), fn('simd_normalize'), t('(right)')],
          [],
          [
            cm(
              '// Combine: joystick width → right, height (negated) → forward',
            ),
          ],
          [k('let'), t(' moveDir = right * jx + forward * (-jy)')],
          [],
          [cm('// --- In the scene update loop ---')],
          [
            k('func'),
            t(' '),
            fn('onSceneUpdate'),
            t('('),
            pm('deltaTime'),
            t(': '),
            tp('Float'),
            t(') {'),
          ],
          [
            t('    '),
            k('let'),
            t(' dt = '),
            fn('min'),
            t('(deltaTime, '),
            nm('1.0'),
            t(' / '),
            nm('30.0'),
            t(')'),
          ],
          [
            t('    '),
            k('let'),
            t(' jx = '),
            tp('Float'),
            t('(joystick.'),
            pr('width'),
            t(')  '),
            cm('// -1…1'),
          ],
          [
            t('    '),
            k('let'),
            t(' jy = '),
            tp('Float'),
            t('(joystick.'),
            pr('height'),
            t(') '),
            cm('// -1…1'),
          ],
          [],
          [
            t('    '),
            k('let'),
            t(' moveDir = '),
            fn('cameraRelativeDir'),
            t('('),
            pm('jx'),
            t(': jx, '),
            pm('jy'),
            t(': jy)'),
          ],
          [
            t('    '),
            k('let'),
            t(' step = '),
            fn('simd_normalize'),
            t('(moveDir) * moveSpeed * dt'),
          ],
          [t('    worldPosition += step')],
          [t('}')],
        ],
        dragging: [
          [k('var'), t(' dragEntity: '), tp('ModelEntity'), t('?')],
          [],
          [
            k('@objc func'),
            t(' '),
            fn('handlePan'),
            t('('),
            k('_'),
            t(' g: '),
            tp('UIPanGestureRecognizer'),
            t(') {'),
          ],
          [
            t('    '),
            k('let'),
            t(' loc = g.'),
            fn('location'),
            t('('),
            pm('in'),
            t(': arView)'),
          ],
          [t('    '), k('switch'), t(' g.'), pr('state'), t(' {')],
          [t('    '), k('case'), t(' .'), en('began'), t(':')],
          [
            t('        dragEntity = arView.'),
            fn('entity'),
            t('('),
            pm('at'),
            t(': loc) '),
            k('as'),
            t('? '),
            tp('ModelEntity'),
          ],
          [t('    '), k('case'), t(' .'), en('changed'), t(':')],
          [t('        '), k('guard let'), t(' e = dragEntity,')],
          [
            t('              '),
            k('let'),
            t(' hit = arView.'),
            fn('raycast'),
            t('('),
            pm('from'),
            t(': loc, '),
            pm('allowing'),
            t(': .'),
            en('estimatedPlane'),
            t(', '),
            pm('alignment'),
            t(': .'),
            en('horizontal'),
            t(').'),
            pr('first'),
          ],
          [t('        '), k('else'), t(' { '), k('return'), t(' }')],
          [
            t('        e.'),
            fn('setPosition'),
            t('(hit.'),
            pr('worldTransform'),
            t('.'),
            fn('translation'),
            t(', '),
            pm('relativeTo'),
            t(': '),
            k('nil'),
            t(')'),
          ],
          [t('    '), k('default'), t(': dragEntity = '), k('nil')],
          [t('    }')],
          [t('}')],
        ],
        usdz: [
          [cm('// Built-in shape primitives')],
          [
            k('let'),
            t(' box = '),
            tp('MeshResource'),
            t('.'),
            fn('generateBox'),
            t('('),
            pm('size'),
            t(': '),
            nm('0.1'),
            t(') '),
            cm('// centered at origin'),
          ],
          [
            k('let'),
            t(' sphere = '),
            tp('MeshResource'),
            t('.'),
            fn('generateSphere'),
            t('('),
            pm('radius'),
            t(': '),
            nm('0.05'),
            t(')'),
          ],
          [
            k('let'),
            t(' plane = '),
            tp('MeshResource'),
            t('.'),
            fn('generatePlane'),
            t('('),
            pm('width'),
            t(': '),
            nm('1'),
            t(', '),
            pm('depth'),
            t(': '),
            nm('1'),
            t(')'),
          ],
          [],
          [cm('// Box extends \u00b10.05 m from its center.')],
          [cm('// On a floor anchor half the box is buried underground.')],
          [cm('// Shift it up by half its height:')],
          [t('box.'), pr('position'), t('.y = '), nm('0.05')],
          [cm('// Or generate with a raised origin:')],
          [
            tp('MeshResource'),
            t('.'),
            fn('generateBox'),
            t('('),
            pm('size'),
            t(': '),
            nm('0.1'),
            t(', '),
            pm('cornerRadius'),
            t(': '),
            nm('0'),
            t(', '),
            pm('origin'),
            t(': ['),
            nm('0'),
            t(', '),
            nm('0.05'),
            t(', '),
            nm('0'),
            t('])'),
          ],
          [],
          [cm('// Load a USDZ from the bundle')],
          [
            k('let'),
            t(' model = '),
            k('try'),
            t(' '),
            k('await'),
            t(' '),
            tp('ModelEntity'),
            t('('),
            pm('named'),
            t(': '),
            st('"toy_car"'),
            t(')'),
          ],
          [],
          [cm('// Enable collision (required for taps, drags, raycasts)')],
          [
            t('model.'),
            fn('generateCollisionShapes'),
            t('('),
            pm('recursive'),
            t(': '),
            k('true'),
            t(')'),
          ],
          [],
          [cm('// Install built-in gestures: tap, drag, rotate, scale')],
          [
            t('arView.'),
            fn('installGestures'),
            t('('),
            pm('.all'),
            t(', '),
            pm('for'),
            t(': model)'),
          ],
          [cm('// .all = .translation | .rotation | .scale')],
          [cm('// Each gesture requires a collision shape on the entity.')],
          [cm('// .translation \u2014 pan to drag on a surface')],
          [cm('// .rotation    \u2014 two-finger twist')],
          [cm('// .scale       \u2014 pinch to resize')],
          [],
          [cm('// Add to the scene')],
          [
            k('let'),
            t(' anchor = '),
            tp('AnchorEntity'),
            t('('),
            pm('plane'),
            t(': .'),
            en('horizontal'),
            t(')'),
          ],
          [t('anchor.'), fn('addChild'), t('(model)')],
          [t('arView.scene.'), fn('addAnchor'), t('(anchor)')],
        ],
        gestures: [
          [cm('// Install gestures and capture the recognizers')],
          [
            t('model.'),
            fn('generateCollisionShapes'),
            t('('),
            pm('recursive'),
            t(': '),
            k('true'),
            t(')'),
          ],
          [
            k('let'),
            t(' gestures = arView.'),
            fn('installGestures'),
            t('('),
            pm('.all'),
            t(', '),
            pm('for'),
            t(': model)'),
          ],
          [],
          [cm('// Add a target to observe each gesture')],
          [k('for'), t(' g '), k('in'), t(' gestures {')],
          [
            t('    g.'),
            fn('addTarget'),
            t('('),
            pm('self'),
            t(', '),
            pm('action'),
            t(': '),
            st('#selector'),
            t('(handleGesture))'),
          ],
          [t('}')],
          [],
          [cm('// Or limit to translation only')],
          [
            t('arView.'),
            fn('installGestures'),
            t('(.'),
            en('translation'),
            t(', '),
            pm('for'),
            t(': model)'),
          ],
          [],
          [
            k('@objc func'),
            t(' '),
            fn('handleGesture'),
            t('('),
            k('_'),
            t(' g: '),
            tp('UIGestureRecognizer'),
            t(') {'),
          ],
          [
            t('    '),
            k('if let'),
            t(' drag = g '),
            k('as'),
            t('? '),
            tp('EntityTranslationGestureRecognizer'),
            t(' {'),
          ],
          [
            t('        '),
            fn('print'),
            t('(drag.'),
            pr('entity'),
            t('?.'),
            pr('position'),
            t(') '),
            cm('// new position'),
          ],
          [t('    }')],
          [
            t('    '),
            k('if let'),
            t(' rot = g '),
            k('as'),
            t('? '),
            tp('EntityRotationGestureRecognizer'),
            t(' {'),
          ],
          [
            t('        '),
            fn('print'),
            t('(rot.'),
            pr('entity'),
            t('?.'),
            pr('orientation'),
            t(') '),
            cm('// new quaternion'),
          ],
          [t('    }')],
          [
            t('    '),
            k('if let'),
            t(' scl = g '),
            k('as'),
            t('? '),
            tp('EntityScaleGestureRecognizer'),
            t(' {'),
          ],
          [
            t('        '),
            fn('print'),
            t('(scl.'),
            pr('entity'),
            t('?.'),
            pr('scale'),
            t(') '),
            cm('// new scale'),
          ],
          [t('    }')],
          [t('}')],
        ],
        raycasting: [
          [cm('// Quick raycast from a screen point')],
          [k('let'), t(' results = arView.'), fn('raycast'), t('(')],
          [t('    '), pm('from'), t(': tapLocation,')],
          [
            t('    '),
            pm('allowing'),
            t(': .'),
            en('estimatedPlane'),
            t(',  '),
            cm('// LiDAR!'),
          ],
          [t('    '), pm('alignment'), t(': .'), en('any')],
          [t(')')],
          [k('if'), t(' '), k('let'), t(' result = results.first {')],
          [
            t('    '),
            k('let'),
            t(' anchor = '),
            tp('AnchorEntity'),
            t('('),
            pm('raycastResult'),
            t(': result)'),
          ],
          [t('    anchor.'), fn('addChild'), t('(myModel)')],
          [t('    arView.scene.'), fn('addAnchor'), t('(anchor)')],
          [t('}')],
          [],
          [cm('// Tracked raycast — refines over time')],
          [
            k('let'),
            t(' tracked = arView.session.'),
            fn('trackedRaycast'),
            t('('),
          ],
          [t('    '), tp('ARRaycastQuery'), t('(')],
          [
            t('        '),
            pm('origin'),
            t(': origin, '),
            pm('direction'),
            t(': dir,'),
          ],
          [
            t('        '),
            pm('allowing'),
            t(': .'),
            en('estimatedPlane'),
            t(','),
          ],
          [t('        '), pm('alignment'), t(': .'), en('any')],
          [t('    )')],
          [t(') { results '), k('in')],
          [
            t('    myAnchor.'),
            pr('transform'),
            t(' = '),
            tp('Transform'),
            t('('),
          ],
          [
            t('        '),
            pm('matrix'),
            t(': results.first!.'),
            pr('worldTransform'),
            t(')'),
          ],
          [t('}')],
          [t('tracked?.'), fn('stopTracking'), t('()')],
        ],
        entityhits: [
          [cm('// Hit test virtual entities (need CollisionComponent)')],
          [k('let'), t(' hits = arView.'), fn('hitTest'), t('(')],
          [
            t('    tapLocation, '),
            pm('query'),
            t(': .'),
            en('nearest'),
            t(', '),
            pm('mask'),
            t(': .'),
            en('all'),
            t(')'),
          ],
          [],
          [k('for'), t(' hit '), k('in'), t(' hits {')],
          [
            t('    hit.'),
            pr('entity'),
            t('     '),
            cm('// The Entity that was hit'),
          ],
          [
            t('    hit.'),
            pr('distance'),
            t('   '),
            cm('// Float — ray to hit'),
          ],
          [
            t('    hit.'),
            pr('position'),
            t('   '),
            cm('// simd_float3 — world'),
          ],
          [t('    hit.'), pr('normal'), t('     '), cm('// surface normal')],
          [t('}')],
          [],
          [cm('// Arbitrary 3D ray (not from screen)')],
          [k('let'), t(' rayHits = arView.scene.'), fn('raycast'), t('(')],
          [
            t('    '),
            pm('origin'),
            t(': '),
            tp('simd_float3'),
            t('('),
            nm('0'),
            t(', '),
            nm('1'),
            t(', '),
            nm('0'),
            t('),'),
          ],
          [
            t('    '),
            pm('direction'),
            t(': '),
            tp('simd_float3'),
            t('('),
            nm('0'),
            t(', -'),
            nm('1'),
            t(', '),
            nm('0'),
            t('),'),
          ],
          [t('    '), pm('length'), t(': '), nm('10.0'), t(',')],
          [t('    '), pm('query'), t(': .'), en('nearest'), t(',')],
          [t('    '), pm('mask'), t(': .'), en('all')],
          [t(')')],
        ],
        interactions: [
          [cm('// 1. entity(at:) \u2014 manual hit-test on virtual objects')],
          [
            k('let'),
            t(' tapped = arView.'),
            fn('entity'),
            t('('),
            pm('at'),
            t(': point)'),
          ],
          [
            t('tapped?.'),
            fn('removeFromParent'),
            t('() '),
            cm('// your logic'),
          ],
          [],
          [cm('// 2. installGestures \u2014 automatic manipulation')],
          [
            t('model.'),
            fn('generateCollisionShapes'),
            t('('),
            pm('recursive'),
            t(': '),
            k('true'),
            t(')'),
          ],
          [
            t('arView.'),
            fn('installGestures'),
            t('(.'),
            en('all'),
            t(', '),
            pm('for'),
            t(': model)'),
          ],
          [cm('// user can now drag, rotate, pinch-scale \u2014 done')],
          [],
          [cm('// 3. raycast \u2014 hit-test the REAL WORLD')],
          [k('let'), t(' hits = arView.'), fn('raycast'), t('(')],
          [t('    '), pm('from'), t(': point,')],
          [t('    '), pm('allowing'), t(': .'), en('estimatedPlane'), t(',')],
          [t('    '), pm('alignment'), t(': .'), en('horizontal')],
          [t(')')],
          [cm('// hits.first?.worldTransform \u2192 place model on floor')],
          [],
          [cm('// Typical flow: combine all three')],
          [cm('// 1. raycast to find the floor')],
          [cm('// 2. spawn a model at the hit point')],
          [cm('// 3. installGestures so user can drag it')],
          [cm('// 4. entity(at:) on long-press to delete/configure')],
        ],
        delegate: [
          [
            k('func'),
            t(' '),
            fn('session'),
            t('('),
            k('_'),
            t(' s: '),
            tp('ARSession'),
            t(', '),
            pm('didUpdate'),
            t(' frame: '),
            tp('ARFrame'),
            t(') {'),
          ],
          [
            t('    '),
            k('let'),
            t(' cameraTransform = frame.camera.'),
            pr('transform'),
          ],
          [t('    '), cm('// LiDAR depth maps')],
          [
            t('    '),
            k('if let'),
            t(' depth = frame.'),
            pr('sceneDepth'),
            t('?.'),
            pr('depthMap'),
            t(' { '),
            cm('/* CVPixelBuffer */'),
            t(' }'),
          ],
          [
            t('    '),
            k('if let'),
            t(' smooth = frame.'),
            pr('smoothedSceneDepth'),
            t('?.'),
            pr('depthMap'),
            t(' { '),
            cm('/* filtered */'),
            t(' }'),
          ],
          [
            t('    '),
            k('if let'),
            t(' conf = frame.'),
            pr('sceneDepth'),
            t('?.'),
            pr('confidenceMap'),
            t(' { '),
            cm('/* 0,1,2 */'),
            t(' }'),
          ],
          [t('}')],
          [],
          [
            k('func'),
            t(' '),
            fn('session'),
            t('('),
            k('_'),
            t(' s: '),
            tp('ARSession'),
            t(', '),
            pm('didAdd'),
            t(' anchors: ['),
            tp('ARAnchor'),
            t(']) {'),
          ],
          [t('    '), k('for'), t(' anchor '), k('in'), t(' anchors {')],
          [
            t('        '),
            k('if let'),
            t(' plane = anchor '),
            k('as'),
            t('? '),
            tp('ARPlaneAnchor'),
            t(' {'),
          ],
          [
            t('            '),
            fn('print'),
            t('(plane.'),
            pr('classification'),
            t(') '),
            cm('// .floor, .wall...'),
          ],
          [t('        }')],
          [
            t('        '),
            k('if let'),
            t(' mesh = anchor '),
            k('as'),
            t('? '),
            tp('ARMeshAnchor'),
            t(' {'),
          ],
          [
            t('            '),
            k('let'),
            t(' geo = mesh.'),
            pr('geometry'),
            t('  '),
            cm('// vertices, faces'),
          ],
          [t('        }')],
          [t('    }')],
          [t('}')],
        ],
        scene: [
          [cm('// LiDAR scene understanding options')],
          [
            t('arView.environment.'),
            pr('sceneUnderstanding'),
            t('.'),
            pr('options'),
            t(' = ['),
          ],
          [
            t('    .'),
            en('occlusion'),
            t(',        '),
            cm('// Hide virtual behind real'),
          ],
          [
            t('    .'),
            en('physics'),
            t(',          '),
            cm('// Collide with real surfaces'),
          ],
          [
            t('    .'),
            en('receivesLighting'),
            t(' '),
            cm('// Real gets virtual shadows'),
          ],
          [t(']')],
          [],
          [cm('// Invisible geometry that hides objects behind it')],
          [k('let'), t(' wall = '), tp('ModelEntity'), t('(')],
          [
            t('    '),
            pm('mesh'),
            t(': .'),
            fn('generateBox'),
            t('('),
            pm('size'),
            t(': '),
            nm('1'),
            t('),'),
          ],
          [
            t('    '),
            pm('materials'),
            t(': ['),
            tp('OcclusionMaterial'),
            t('()]'),
          ],
          [t(')')],
          [],
          [cm('// Debug visualization')],
          [t('arView.'), pr('debugOptions'), t(' = [')],
          [
            t('    .'),
            en('showSceneUnderstanding'),
            t(',  '),
            cm('// LiDAR mesh wireframe'),
          ],
          [
            t('    .'),
            en('showWorldOrigin'),
            t(',         '),
            cm('// X/Y/Z axes at (0,0,0)'),
          ],
          [
            t('    .'),
            en('showAnchorOrigins'),
            t(',       '),
            cm('// Anchor positions'),
          ],
          [
            t('    .'),
            en('showFeaturePoints'),
            t(',       '),
            cm('// Tracked point cloud'),
          ],
          [
            t('    .'),
            en('showPhysics'),
            t('              '),
            cm('// Physics debug shapes'),
          ],
          [t(']')],
        ],
        tap: [
          [
            t('@objc '),
            k('func'),
            t(' '),
            fn('handleTap'),
            t('('),
            k('_'),
            t(' rec: '),
            tp('UITapGestureRecognizer'),
            t(') {'),
          ],
          [
            t('    '),
            k('guard let'),
            t(' arView = rec.view '),
            k('as'),
            t('? '),
            tp('ARView'),
            t(' '),
            k('else'),
            t(' { '),
            k('return'),
            t(' }'),
          ],
          [
            t('    '),
            k('let'),
            t(' tap = rec.'),
            fn('location'),
            t('('),
            pm('in'),
            t(': arView)'),
          ],
          [],
          [t('    '), cm('// First: check if we tapped an existing entity')],
          [
            t('    '),
            k('if let'),
            t(' hit = arView.'),
            fn('hitTest'),
            t('(tap, '),
            pm('query'),
            t(': .'),
            en('nearest'),
            t(').first {'),
          ],
          [
            t('        '),
            fn('print'),
            t('('),
            st('"Tapped: \\(hit.entity.name)"'),
            t(')'),
          ],
          [t('        '), k('return')],
          [t('    }')],
          [],
          [t('    '), cm('// Then: raycast to place new object')],
          [t('    '), k('let'), t(' results = arView.'), fn('raycast'), t('(')],
          [
            t('        '),
            pm('from'),
            t(': tap, '),
            pm('allowing'),
            t(': .'),
            en('estimatedPlane'),
            t(', '),
            pm('alignment'),
            t(': .'),
            en('any'),
            t(')'),
          ],
          [t('    '), k('if let'), t(' result = results.first {')],
          [
            t('        '),
            k('let'),
            t(' model = '),
            k('try!'),
            t(' '),
            tp('ModelEntity'),
            t('.'),
            fn('loadModel'),
            t('('),
            pm('named'),
            t(': '),
            st('"toy_car"'),
            t(')'),
          ],
          [
            t('        model.'),
            fn('generateCollisionShapes'),
            t('('),
            pm('recursive'),
            t(': '),
            k('true'),
            t(')'),
          ],
          [
            t('        '),
            k('let'),
            t(' anchor = '),
            tp('AnchorEntity'),
            t('('),
            pm('raycastResult'),
            t(': result)'),
          ],
          [t('        anchor.'), fn('addChild'), t('(model)')],
          [t('        arView.scene.'), fn('addAnchor'), t('(anchor)')],
          [
            t('        arView.'),
            fn('installGestures'),
            t('(.'),
            en('all'),
            t(', '),
            pm('for'),
            t(': model)'),
          ],
          [t('    }')],
          [t('}')],
        ],
        mesh: [
          [
            k('func'),
            t(' '),
            fn('session'),
            t('('),
            k('_'),
            t(' s: '),
            tp('ARSession'),
            t(', '),
            pm('didUpdate'),
            t(' anchors: ['),
            tp('ARAnchor'),
            t(']) {'),
          ],
          [t('    '), k('for'), t(' anchor '), k('in'), t(' anchors {')],
          [
            t('        '),
            k('guard let'),
            t(' m = anchor '),
            k('as'),
            t('? '),
            tp('ARMeshAnchor'),
            t(' '),
            k('else'),
            t(' { '),
            k('continue'),
            t(' }'),
          ],
          [t('        '), k('let'), t(' geo = m.'), pr('geometry')],
          [],
          [
            t('        '),
            k('let'),
            t(' vertices = geo.'),
            pr('vertices'),
            t('       '),
            cm('// ARGeometrySource'),
          ],
          [
            t('        '),
            k('let'),
            t(' faces = geo.'),
            pr('faces'),
            t('             '),
            cm('// ARGeometryElement'),
          ],
          [
            t('        '),
            k('let'),
            t(' normals = geo.'),
            pr('normals'),
            t('         '),
            cm('// ARGeometrySource'),
          ],
          [
            t('        '),
            k('let'),
            t(' classification = geo.'),
            pr('classification'),
          ],
          [t('        '), cm('// Per-face: 0=none, 1=wall, 2=floor,')],
          [
            t('        '),
            cm('//   3=ceiling, 4=table, 5=seat, 6=door, 7=window'),
          ],
          [],
          [t('        '), cm('// Transform vertices to world space')],
          [
            t('        '),
            k('let'),
            t(' worldT = m.'),
            pr('transform'),
            t('  '),
            cm('// simd_float4x4'),
          ],
          [t('    }')],
          [t('}')],
        ],
        outline: [
          [cm('// 1. Respond to plane anchor updates')],
          [
            k('func'),
            t(' '),
            fn('session'),
            t('(_ s: '),
            tp('ARSession'),
            t(', '),
            pm('didAdd'),
            t(' anchors: ['),
            tp('ARAnchor'),
            t(']) {'),
          ],
          [t('    '), k('for'), t(' anchor '), k('in'), t(' anchors {')],
          [
            t('        '),
            k('guard let'),
            t(' plane = anchor '),
            k('as'),
            t('? '),
            tp('ARPlaneAnchor'),
            t(' '),
            k('else'),
            t(' { '),
            k('continue'),
            t(' }'),
          ],
          [
            t('        '),
            fn('updatePlaneOutline'),
            t('('),
            pm('for'),
            t(': plane)'),
          ],
          [t('    }')],
          [],
          [cm('// 2. Walk boundary vertices to build edge quads')],
          [
            k('func'),
            t(' '),
            fn('buildOutlineMesh'),
            t('('),
            pm('from'),
            t(' plane: '),
            tp('ARPlaneAnchor'),
            t(') -> '),
            tp('MeshResource'),
            t('? {'),
          ],
          [
            t('    '),
            k('let'),
            t(' boundary = plane.'),
            pr('geometry'),
            t('.'),
            pr('boundaryVertices'),
          ],
          [
            t('    '),
            k('guard'),
            t(' boundary.'),
            pr('count'),
            t(' >= '),
            nm('3'),
            t(' '),
            k('else'),
            t(' { '),
            k('return'),
            t(' '),
            k('nil'),
            t(' }'),
          ],
          [
            t('    '),
            k('let'),
            t(' half: '),
            tp('Float'),
            t(' = '),
            nm('0.005'),
            t(' / '),
            nm('2'),
          ],
          [
            t('    '),
            k('let'),
            t(' up = '),
            tp('SIMD3'),
            t('<'),
            tp('Float'),
            t('>('),
            nm('0'),
            t(','),
            nm('1'),
            t(','),
            nm('0'),
            t(')'),
          ],
          [t('    '), k('let'), t(' upOffset = up * '), nm('0.002')],
          [],
          [
            t('    '),
            k('var'),
            t(' positions: ['),
            tp('SIMD3'),
            t('<'),
            tp('Float'),
            t('>] = []'),
          ],
          [
            t('    '),
            k('var'),
            t(' normals:   ['),
            tp('SIMD3'),
            t('<'),
            tp('Float'),
            t('>] = []'),
          ],
          [t('    '), k('var'), t(' indices:   ['), tp('UInt32'), t('] = []')],
          [],
          [cm('// 3. For each edge, compute perpendicular offset')],
          [
            t('    '),
            k('for'),
            t(' i '),
            k('in'),
            t(' '),
            nm('0'),
            t('..< boundary.'),
            pr('count'),
            t(' {'),
          ],
          [t('        '), k('let'), t(' v0 = boundary[i]')],
          [
            t('        '),
            k('let'),
            t(' v1 = boundary[(i+'),
            nm('1'),
            t(') % boundary.'),
            pr('count'),
            t(']'),
          ],
          [
            t('        '),
            k('let'),
            t(' edgeDir = '),
            fn('simd_normalize'),
            t('(v1 - v0)'),
          ],
          [
            t('        '),
            k('var'),
            t(' right = '),
            fn('simd_cross'),
            t('(edgeDir, up)'),
          ],
          [t('        right = '), fn('simd_normalize'), t('(right) * half')],
          [],
          [
            t('        '),
            k('let'),
            t(' base = '),
            tp('UInt32'),
            t('(positions.'),
            pr('count'),
            t(')'),
          ],
          [t('        '), cm('// Quad: 4 verts, 2 triangles per edge')],
          [t('        positions += [v0-right+upOffset, v0+right+upOffset,')],
          [t('                      v1+right+upOffset, v1-right+upOffset]')],
          [t('        normals += [up, up, up, up]')],
          [
            t('        indices += [base, base+'),
            nm('1'),
            t(', base+'),
            nm('2'),
            t(','),
          ],
          [
            t('                    base, base+'),
            nm('2'),
            t(', base+'),
            nm('3'),
            t(']'),
          ],
          [t('    }')],
          [],
          [cm('// 4. Create or update the outline entity')],
          [
            k('func'),
            t(' '),
            fn('updatePlaneOutline'),
            t('('),
            pm('for'),
            t(' plane: '),
            tp('ARPlaneAnchor'),
            t(') {'),
          ],
          [
            t('    '),
            k('guard let'),
            t(' mesh = '),
            fn('buildOutlineMesh'),
            t('('),
            pm('from'),
            t(': plane) '),
            k('else'),
            t(' { '),
            k('return'),
            t(' }'),
          ],
          [
            t('    '),
            k('var'),
            t(' mat = '),
            tp('UnlitMaterial'),
            t('('),
            pm('color'),
            t(': .'),
            en('white'),
            t(')'),
          ],
          [
            t('    mat.'),
            pr('blending'),
            t(' = .'),
            fn('transparent'),
            t('('),
            pm('opacity'),
            t(': '),
            nm('0.7'),
            t(')'),
          ],
          [],
          [
            t('    '),
            k('if let'),
            t(' existing = outlines[plane.'),
            pr('identifier'),
            t('] {'),
          ],
          [
            t('        existing.'),
            pr('model'),
            t('?.'),
            pr('mesh'),
            t(' = mesh'),
          ],
          [
            t('        existing.'),
            pr('transform'),
            t(' = '),
            tp('Transform'),
            t('('),
            pm('matrix'),
            t(': plane.'),
            pr('transform'),
            t(')'),
          ],
          [t('    } '), k('else'), t(' {')],
          [
            t('        '),
            k('let'),
            t(' entity = '),
            tp('ModelEntity'),
            t('('),
            pm('mesh'),
            t(': mesh, '),
            pm('materials'),
            t(': [mat])'),
          ],
          [
            t('        '),
            k('let'),
            t(' anchor = '),
            tp('AnchorEntity'),
            t('('),
            pm('world'),
            t(': .'),
            en('zero'),
            t(')'),
          ],
          [
            t('        anchor.'),
            pr('transform'),
            t(' = '),
            tp('Transform'),
            t('('),
            pm('matrix'),
            t(': plane.'),
            pr('transform'),
            t(')'),
          ],
          [t('        anchor.'), fn('addChild'), t('(entity)')],
          [t('        arView.scene.'), fn('addAnchor'), t('(anchor)')],
          [t('        outlines[plane.'), pr('identifier'), t('] = entity')],
          [t('    }')],
          [t('}')],
        ],
        handpinch: [
          [cm('// 1. Set up hand-pose detection')],
          [
            k('let'),
            t(' handPoseRequest = '),
            tp('VNDetectHumanHandPoseRequest'),
            t('()'),
          ],
          [t('handPoseRequest.'), pr('maximumHandCount'), t(' = '), nm('2')],
          [k('var'), t(' wasPinching = '), k('false')],
          [k('var'), t(' pinnedEntity: '), tp('ModelEntity'), t('?')],
          [],
          [cm('// 2. Run detection on each AR frame')],
          [
            k('func'),
            t(' '),
            fn('session'),
            t('(_ session: '),
            tp('ARSession'),
            t(', '),
            pm('didUpdate'),
            t(' frame: '),
            tp('ARFrame'),
            t(') {'),
          ],
          [
            t('    '),
            k('let'),
            t(' pixelBuffer = frame.'),
            pr('capturedImage'),
          ],
          [
            t('    '),
            k('let'),
            t(' handler = '),
            tp('VNImageRequestHandler'),
            t('('),
          ],
          [t('        '), pm('cvPixelBuffer'), t(': pixelBuffer,')],
          [
            t('        '),
            pm('orientation'),
            t(': .'),
            en('right'),
            t(', '),
            pm('options'),
            t(': [:]'),
          ],
          [t('    )')],
          [
            t('    '),
            k('try'),
            t(' handler.'),
            fn('perform'),
            t('([handPoseRequest])'),
          ],
          [
            t('    '),
            k('guard let'),
            t(' results = handPoseRequest.'),
            pr('results'),
          ],
          [t('        '), k('else'), t(' { '), k('return'), t(' }')],
          [
            t('    '),
            fn('processHands'),
            t('(results, '),
            pm('in'),
            t(': arView)'),
          ],
          [t('}')],
          [],
          [cm('// 3. Detect thumb–index pinch')],
          [k('func'), t(' '), fn('detectPinch'), t('(')],
          [
            t('    '),
            pm('observation'),
            t(': '),
            tp('VNHumanHandPoseObservation'),
            t(','),
          ],
          [t('    '), pm('in'), t(' arView: '), tp('ARView')],
          [t(') -> ('), tp('Bool'), t(', '), tp('CGPoint'), t(')? {')],
          [
            t('    '),
            k('let'),
            t(' thumb  = '),
            k('try'),
            t(' observation.'),
            fn('recognizedPoint'),
            t('(.'),
            en('thumbTip'),
            t(')'),
          ],
          [
            t('    '),
            k('let'),
            t(' index  = '),
            k('try'),
            t(' observation.'),
            fn('recognizedPoint'),
            t('(.'),
            en('indexTip'),
            t(')'),
          ],
          [
            t('    '),
            k('guard'),
            t(' thumb.'),
            pr('confidence'),
            t(' > '),
            nm('0.3'),
            t(','),
          ],
          [
            t('          index.'),
            pr('confidence'),
            t(' > '),
            nm('0.3'),
            t(' '),
            k('else'),
            t(' { '),
            k('return'),
            t(' '),
            k('nil'),
            t(' }'),
          ],
          [],
          [
            t('    '),
            k('let'),
            t(' dist = '),
            fn('hypot'),
            t('(thumb.'),
            pr('location'),
            t('.x - index.'),
            pr('location'),
            t('.x,'),
          ],
          [
            t('                       thumb.'),
            pr('location'),
            t('.y - index.'),
            pr('location'),
            t('.y)'),
          ],
          [
            t('    '),
            k('let'),
            t(' isPinch = dist < '),
            nm('0.05'),
            t('  '),
            cm('// normalised threshold'),
          ],
          [],
          [t('    '), cm('// Midpoint → screen coords (flip Y for UIKit)')],
          [
            t('    '),
            k('let'),
            t(' mx = (thumb.'),
            pr('location'),
            t('.x + index.'),
            pr('location'),
            t('.x) / '),
            nm('2'),
          ],
          [
            t('    '),
            k('let'),
            t(' my = (thumb.'),
            pr('location'),
            t('.y + index.'),
            pr('location'),
            t('.y) / '),
            nm('2'),
          ],
          [
            t('    '),
            k('let'),
            t(' pt = '),
            tp('CGPoint'),
            t('('),
            pm('x'),
            t(': mx * arView.'),
            pr('bounds'),
            t('.'),
            pr('width'),
            t(','),
          ],
          [
            t('                       '),
            pm('y'),
            t(': ('),
            nm('1'),
            t(' - my) * arView.'),
            pr('bounds'),
            t('.'),
            pr('height'),
            t(')'),
          ],
          [t('    '), k('return'), t(' (isPinch, pt)')],
          [t('}')],
          [],
          [cm('// 4. Grab, drag, and release')],
          [
            k('func'),
            t(' '),
            fn('handlePinch'),
            t('('),
            pm('isPinching'),
            t(': '),
            tp('Bool'),
            t(', '),
            pm('at'),
            t(' pt: '),
            tp('CGPoint'),
            t('?) {'),
          ],
          [t('    '), k('if'), t(' isPinching && !wasPinching,')],
          [t('       '), k('let'), t(' pt,')],
          [
            t('       '),
            k('let'),
            t(' hit = arView.'),
            fn('entity'),
            t('('),
            pm('at'),
            t(': pt) '),
            k('as'),
            t('? '),
            tp('ModelEntity'),
            t(' {'),
          ],
          [t('        pinnedEntity = hit')],
          [t('        dragDist = '), fn('simd_distance'), t('(')],
          [
            t('            arView.'),
            pr('cameraTransform'),
            t('.'),
            pr('translation'),
            t(','),
          ],
          [
            t('            hit.'),
            fn('position'),
            t('('),
            pm('relativeTo'),
            t(': '),
            k('nil'),
            t(')'),
          ],
          [t('        )')],
          [
            t('        hit.'),
            pr('physicsBody'),
            t('?.'),
            pr('mode'),
            t(' = .'),
            en('kinematic'),
          ],
          [],
          [
            t('    } '),
            k('else'),
            t(' '),
            k('if'),
            t(' isPinching, '),
            k('let'),
            t(' entity = pinnedEntity,'),
          ],
          [
            t('       '),
            k('let'),
            t(' pt, '),
            k('let'),
            t(' ray = arView.'),
            fn('ray'),
            t('('),
            pm('through'),
            t(': pt) {'),
          ],
          [
            t('        '),
            k('let'),
            t(' pos = ray.'),
            pr('origin'),
            t(' + ray.'),
            pr('direction'),
            t(' * dragDist'),
          ],
          [
            t('        entity.'),
            fn('setPosition'),
            t('(pos, '),
            pm('relativeTo'),
            t(': '),
            k('nil'),
            t(')'),
          ],
          [],
          [
            t('    } '),
            k('else'),
            t(' '),
            k('if'),
            t(' !isPinching, '),
            k('let'),
            t(' entity = pinnedEntity {'),
          ],
          [
            t('        entity.'),
            pr('physicsBody'),
            t('?.'),
            pr('mode'),
            t(' = .'),
            en('dynamic'),
          ],
          [t('        pinnedEntity = '), k('nil')],
          [t('    }')],
          [t('    wasPinching = isPinching')],
          [t('}')],
        ],
        usdzanim: [
          [cm('// Load a USDZ that contains animations')],
          [
            k('let'),
            t(' robot = '),
            k('try'),
            t(' '),
            k('await'),
            t(' '),
            tp('Entity'),
            t('('),
            pm('named'),
            t(': '),
            st('"robot"'),
            t(')'),
          ],
          [
            k('let'),
            t(' anchor = '),
            tp('AnchorEntity'),
            t('('),
            pm('plane'),
            t(': .'),
            en('horizontal'),
            t(')'),
          ],
          [t('anchor.'), fn('addChild'), t('(robot)')],
          [],
          [cm('// Discover all embedded animation clips')],
          [k('let'), t(' anims = robot.'), pr('availableAnimations')],
          [k('for'), t(' anim '), k('in'), t(' anims {')],
          [
            t('    '),
            fn('print'),
            t('('),
            st('"Animation:"'),
            t(', anim.'),
            pr('name'),
            t(' ?? '),
            st('"unnamed"'),
            t(')'),
          ],
          [t('}')],
          [cm('// availableAnimations: [AnimationResource]')],
          [],
          [cm('// Play the first animation')],
          [
            k('if'),
            t(' '),
            k('let'),
            t(' first = anims.'),
            pr('first'),
            t(' {'),
          ],
          [
            t('    '),
            k('let'),
            t(' controller = robot.'),
            fn('playAnimation'),
            t('(first)'),
          ],
          [t('    '), cm('// controller: AnimationPlaybackController')],
          [t('}')],
          [],
          [cm('// Control playback')],
          [t('controller.'), fn('pause'), t('()')],
          [t('controller.'), fn('resume'), t('()')],
          [t('controller.'), fn('stop'), t('()')],
          [
            t('controller.'),
            pr('speed'),
            t(' = '),
            nm('2.0'),
            t('  '),
            cm('// double speed'),
          ],
          [
            t('controller.'),
            pr('speed'),
            t(' = '),
            nm('-1.0'),
            t(' '),
            cm('// play in reverse'),
          ],
          [cm('// .blendFactor adjusts influence (0.0 – 1.0)')],
          [],
          [cm('// Loop forever')],
          [
            k('let'),
            t(' looped = anims['),
            nm('0'),
            t('].'),
            fn('repeat'),
            t('()'),
          ],
          [t('robot.'), fn('playAnimation'), t('(looped)')],
          [],
          [cm('// Repeat a fixed number of times')],
          [
            k('let'),
            t(' thrice = anims['),
            nm('0'),
            t('].'),
            fn('repeat'),
            t('('),
            pm('count'),
            t(': '),
            nm('3'),
            t(')'),
          ],
          [t('robot.'), fn('playAnimation'), t('(thrice)')],
          [],
          [cm('// Sequence: play walk then idle back-to-back')],
          [k('let'), t(' walk = anims['), nm('0'), t(']')],
          [k('let'), t(' idle = anims['), nm('1'), t(']')],
          [
            k('let'),
            t(' sequence = '),
            k('try'),
            t(' '),
            tp('AnimationResource'),
            t('.'),
          ],
          [t('    '), fn('sequence'), t('('), pm('with'), t(': [walk, idle])')],
          [t('robot.'), fn('playAnimation'), t('(sequence)')],
          [],
          [cm('// Blend: crossfade from current to new animation')],
          [t('robot.'), fn('playAnimation'), t('(')],
          [
            t('    idle, '),
            pm('transitionDuration'),
            t(': '),
            nm('0.5'),
            t(')  '),
            cm('// 0.5s crossfade'),
          ],
        ],
        meshcross: [
          [cm('// Detect when real-world geometry crosses')],
          [cm('// an invisible vertical plane 1 m ahead')],
          [],
          [cm('// The math: dot(vertex − planePoint, normal)')],
          [cm('//   > 0 → same side as camera (in front of plane)')],
          [cm('//   < 0 → far side (crossed the plane)')],
          [],
          [cm('// 1. Define the plane at session start')],
          [k('let'), t(' cam = frame.'), pr('camera'), t('.'), pr('transform')],
          [
            k('let'),
            t(' fwd = '),
            tp('SIMD3'),
            t('<'),
            tp('Float'),
            t('>(cam.columns.'),
            nm('2'),
            t('.x,'),
          ],
          [t('                      cam.columns.'), nm('2'), t('.y,')],
          [t('                      cam.columns.'), nm('2'), t('.z)')],
          [
            k('let'),
            t(' pos = '),
            tp('SIMD3'),
            t('<'),
            tp('Float'),
            t('>(cam.columns.'),
            nm('3'),
            t('.x,'),
          ],
          [t('                      cam.columns.'), nm('3'), t('.y,')],
          [t('                      cam.columns.'), nm('3'), t('.z)')],
          [t('planePoint  = pos - fwd '), cm('// 1 m ahead')],
          [
            t('planeNormal = '),
            fn('simd_normalize'),
            t('(fwd) '),
            cm('// faces back toward camera'),
          ],
          [],
          [cm('// 2. Each frame, test mesh vertices against the plane')],
          [
            k('func'),
            t(' '),
            fn('session'),
            t('(_ s: '),
            tp('ARSession'),
            t(', '),
            pm('didUpdate'),
            t(' anchors: ['),
            tp('ARAnchor'),
            t(']) {'),
          ],
          [t('    '), k('var'), t(' crossCount = '), nm('0')],
          [],
          [t('    '), k('for'), t(' anchor '), k('in'), t(' anchors {')],
          [
            t('        '),
            k('guard let'),
            t(' mesh = anchor '),
            k('as'),
            t('? '),
            tp('ARMeshAnchor'),
            t(' '),
            k('else'),
            t(' { '),
            k('continue'),
            t(' }'),
          ],
          [
            t('        '),
            k('let'),
            t(' verts = mesh.'),
            pr('geometry'),
            t('.'),
            pr('vertices'),
          ],
          [t('        '), k('let'), t(' meshT = mesh.'), pr('transform')],
          [],
          [
            t('        '),
            k('for'),
            t(' i '),
            k('in'),
            t(' '),
            nm('0'),
            t('..<verts.'),
            pr('count'),
            t(' {'),
          ],
          [
            t('            '),
            cm('// Get vertex in local space, transform to world'),
          ],
          [t('            '), k('let'), t(' localV = verts[i]')],
          [
            t('            '),
            k('let'),
            t(' world4 = meshT * '),
            tp('simd_float4'),
            t('(localV, '),
            nm('1'),
            t(')'),
          ],
          [
            t('            '),
            k('let'),
            t(' worldV = '),
            tp('SIMD3'),
            t('<'),
            tp('Float'),
            t('>(world4.x, world4.y, world4.z)'),
          ],
          [],
          [t('            '), cm('// dot < 0 means vertex is past the plane')],
          [
            t('            '),
            k('let'),
            t(' d = '),
            fn('simd_dot'),
            t('(worldV - planePoint, planeNormal)'),
          ],
          [
            t('            '),
            k('if'),
            t(' d < '),
            nm('0'),
            t(' { crossCount += '),
            nm('1'),
            t(' }'),
          ],
          [t('        }')],
          [t('    }')],
          [],
          [
            t('    '),
            cm('// 3. Enough vertices crossed → something broke the plane'),
          ],
          [t('    '), k('if'), t(' crossCount > '), nm('10'), t(' {')],
          [
            t('        '),
            fn('print'),
            t('('),
            st('"Object crossed the plane!"'),
            t(')'),
          ],
          [t('        '), cm('// trigger haptic, sound, game event, etc.')],
          [t('    }')],
          [t('}')],
        ],
      };
      Object.keys(C).forEach((k) => {
        const el = document.getElementById('code-' + k);
        if (!el) return;
        C[k].forEach((toks, i) => {
          const d = document.createElement('div');
          d.className = 'cl';
          d.dataset.line = i + 1;
          const ln = document.createElement('span');
          ln.className = 'ln';
          ln.textContent = i + 1;
          d.appendChild(ln);
          const c = document.createElement('code');
          if (!toks.length) c.innerHTML = '\u00a0';
          else
            toks.forEach((tk) => {
              if (tk.c) {
                const s = document.createElement('span');
                s.className = tk.c;
                s.textContent = tk.t;
                c.appendChild(s);
              } else c.appendChild(document.createTextNode(tk.t));
            });
          d.appendChild(c);
          el.appendChild(d);
        });
      });
      const obs = new IntersectionObserver(
        (es) => {
          es.forEach((e) => {
            if (e.isIntersecting && e.intersectionRatio > 0.3) {
              e.target.classList.add('active');
              const sec = e.target.closest('.section');
              if (!sec) return;
              const body = sec.querySelector('.code-scroll');
              if (!body) return;
              body
                .querySelectorAll('.cl')
                .forEach((l) => l.classList.remove('hl'));
              const r = e.target.dataset.hl;
              if (!r) return;
              const [s, end] = r.split('-').map(Number);
              const lines = body.querySelectorAll('.cl');
              for (let i = s - 1; i <= end - 1 && i < lines.length; i++)
                lines[i].classList.add('hl');
              const first = lines[s - 1];
              if (first) {
                const cr = body.getBoundingClientRect();
                const lr = first.getBoundingClientRect();
                body.scrollTo({
                  top: body.scrollTop + lr.top - cr.top - cr.height / 4,
                  behavior: 'smooth',
                });
              }
            } else e.target.classList.remove('active');
          });
        },
        { threshold: [0, 0.3, 0.6, 1], rootMargin: '-15% 0px -15% 0px' },
      );
      document.querySelectorAll('.expl').forEach((b) => obs.observe(b));
    </script>

    <script type="module">
      import * as THREE from 'three';
      import { OrbitControls } from 'three/addons/controls/OrbitControls.js';

      function initCoords(canvasId) {
        const canvas = document.getElementById(canvasId);
        if (!canvas) return;

        const renderer = new THREE.WebGLRenderer({
          canvas,
          antialias: true,
          alpha: true,
        });
        renderer.setPixelRatio(Math.min(window.devicePixelRatio, 2));
        renderer.setSize(canvas.width, canvas.height, false);
        renderer.setClearColor(0xfafafa, 1);

        const scene = new THREE.Scene();
        const camera = new THREE.PerspectiveCamera(
          35,
          canvas.width / canvas.height,
          0.1,
          50,
        );
        camera.position.set(2.5, 2, 3.5);
        camera.lookAt(0, 0.3, 0);

        const controls = new OrbitControls(camera, canvas);
        controls.enableDamping = true;
        controls.dampingFactor = 0.08;
        controls.enableZoom = false;
        controls.enablePan = false;
        controls.autoRotate = true;
        controls.autoRotateSpeed = 1.2;

        // Grid
        const grid = new THREE.GridHelper(4, 8, 0xdddddd, 0xeeeeee);
        scene.add(grid);

        // Axis shafts
        const axLen = 1.6;
        const cols = { x: 0xff3b30, y: 0x34c759, z: 0x007aff };

        function makeAxis(dir, color) {
          const mat = new THREE.MeshBasicMaterial({ color });
          // shaft
          const geo = new THREE.CylinderGeometry(0.025, 0.025, axLen, 8);
          const shaft = new THREE.Mesh(geo, mat);
          shaft.position.copy(dir.clone().multiplyScalar(axLen / 2));
          if (dir.x) shaft.rotation.z = -Math.PI / 2;
          if (dir.z) shaft.rotation.x = Math.PI / 2;
          scene.add(shaft);
          // cone
          const cGeo = new THREE.ConeGeometry(0.06, 0.18, 12);
          const cone = new THREE.Mesh(cGeo, mat);
          cone.position.copy(dir.clone().multiplyScalar(axLen + 0.09));
          if (dir.x) cone.rotation.z = -Math.PI / 2;
          if (dir.z) cone.rotation.x = Math.PI / 2;
          scene.add(cone);
          return { shaft, cone };
        }
        makeAxis(new THREE.Vector3(1, 0, 0), cols.x);
        makeAxis(new THREE.Vector3(0, 1, 0), cols.y);
        makeAxis(new THREE.Vector3(0, 0, 1), cols.z);

        // Labels
        function makeLabel(text, pos, color) {
          const c2 = document.createElement('canvas');
          c2.width = 64;
          c2.height = 32;
          const ctx = c2.getContext('2d');
          ctx.font = 'bold 22px Inter, sans-serif';
          ctx.textAlign = 'center';
          ctx.textBaseline = 'middle';
          ctx.fillStyle = color;
          ctx.fillText(text, 32, 16);
          const tex = new THREE.CanvasTexture(c2);
          const sp = new THREE.Sprite(
            new THREE.SpriteMaterial({ map: tex, depthTest: false }),
          );
          sp.position.copy(pos);
          sp.scale.set(0.5, 0.25, 1);
          scene.add(sp);
        }
        makeLabel('+X', new THREE.Vector3(axLen + 0.4, 0, 0), '#ff3b30');
        makeLabel('+Y', new THREE.Vector3(0, axLen + 0.35, 0), '#34c759');
        makeLabel('+Z', new THREE.Vector3(0, 0, axLen + 0.4), '#007aff');

        // Camera frustum wireframe
        const frustumGroup = new THREE.Group();
        const fl = 0.6,
          fn = 0.15,
          ff = 0.45;
        const verts = [
          // near plane
          new THREE.Vector3(-fn, -fn * 0.75, 0),
          new THREE.Vector3(fn, -fn * 0.75, 0),
          new THREE.Vector3(fn, fn * 0.75, 0),
          new THREE.Vector3(-fn, fn * 0.75, 0),
          // far plane
          new THREE.Vector3(-ff, -ff * 0.75, -fl),
          new THREE.Vector3(ff, -ff * 0.75, -fl),
          new THREE.Vector3(ff, ff * 0.75, -fl),
          new THREE.Vector3(-ff, ff * 0.75, -fl),
        ];
        const edges = [
          [0, 1],
          [1, 2],
          [2, 3],
          [3, 0],
          [4, 5],
          [5, 6],
          [6, 7],
          [7, 4],
          [0, 4],
          [1, 5],
          [2, 6],
          [3, 7],
        ];
        const lineMat = new THREE.LineBasicMaterial({ color: 0x8e8e93 });
        edges.forEach(([a, b]) => {
          const g = new THREE.BufferGeometry().setFromPoints([
            verts[a],
            verts[b],
          ]);
          frustumGroup.add(new THREE.Line(g, lineMat));
        });
        // lens circle
        const lensGeo = new THREE.RingGeometry(0.07, 0.09, 16);
        const lensMat = new THREE.MeshBasicMaterial({
          color: 0x8e8e93,
          side: THREE.DoubleSide,
        });
        const lens = new THREE.Mesh(lensGeo, lensMat);
        frustumGroup.add(lens);
        // –Z label
        makeLabel('–Z', new THREE.Vector3(0, 0.35, -fl * 0.5), '#8e8e93');

        frustumGroup.position.set(0, 0.8, 0);
        scene.add(frustumGroup);

        // Origin sphere
        const originGeo = new THREE.SphereGeometry(0.06, 16, 16);
        const originMat = new THREE.MeshBasicMaterial({ color: 0x1a1a1a });
        scene.add(new THREE.Mesh(originGeo, originMat));

        // Visibility observer — only animate when canvas is on screen
        let visible = false;
        const vObs = new IntersectionObserver(
          ([e]) => {
            visible = e.isIntersecting;
          },
          { threshold: 0.1 },
        );
        vObs.observe(canvas);

        function tick() {
          requestAnimationFrame(tick);
          if (!visible) return;
          controls.update();
          renderer.render(scene, camera);
        }
        tick();
      }

      initCoords('scene-coords');

      /* ── Matrix column-vector visualisation ── */
      function initMatrixViz(canvasId) {
        const canvas = document.getElementById(canvasId);
        if (!canvas) return;
        const renderer = new THREE.WebGLRenderer({
          canvas,
          antialias: true,
          alpha: true,
        });
        renderer.setPixelRatio(Math.min(window.devicePixelRatio, 2));
        renderer.setSize(canvas.width, canvas.height, false);
        renderer.setClearColor(0xfafafa, 1);

        const scene = new THREE.Scene();
        const cam = new THREE.PerspectiveCamera(
          32,
          canvas.width / canvas.height,
          0.1,
          50,
        );
        cam.position.set(2.2, 1.8, 3.0);
        cam.lookAt(0, 0.25, 0);

        const controls = new OrbitControls(cam, canvas);
        controls.enableDamping = true;
        controls.dampingFactor = 0.08;
        controls.enableZoom = false;
        controls.enablePan = false;
        controls.autoRotate = true;
        controls.autoRotateSpeed = 1.0;

        // Light grid
        scene.add(new THREE.GridHelper(3, 6, 0xdddddd, 0xeeeeee));

        // Phone body (thin box standing upright)
        const phoneMat = new THREE.MeshBasicMaterial({
          color: 0x1a1a1a,
          transparent: true,
          opacity: 0.5,
        });
        const phoneGeo = new THREE.BoxGeometry(0.38, 0.6, 0.04);
        const phone = new THREE.Mesh(phoneGeo, phoneMat);
        phone.position.set(0, 0.55, 0);
        scene.add(phone);

        // Lens dot
        const lensMat = new THREE.MeshBasicMaterial({ color: 0x8e8e93 });
        const lens = new THREE.Mesh(
          new THREE.CircleGeometry(0.04, 16),
          lensMat,
        );
        lens.position.set(0, 0.75, -0.021);
        scene.add(lens);

        // Column arrows helper
        const arrowLen = 1.0;
        function makeArrow(dir, origin, color, label) {
          const d = dir.clone().normalize();
          const arr = new THREE.ArrowHelper(
            d,
            origin,
            arrowLen,
            color,
            0.14,
            0.08,
          );
          scene.add(arr);
          // label sprite
          const c2 = document.createElement('canvas');
          c2.width = 128;
          c2.height = 48;
          const ctx = c2.getContext('2d');
          ctx.font = 'bold 28px Inter, sans-serif';
          ctx.textAlign = 'center';
          ctx.textBaseline = 'middle';
          ctx.fillStyle = '#' + color.toString(16).padStart(6, '0');
          ctx.fillText(label, 64, 24);
          const tex = new THREE.CanvasTexture(c2);
          const sp = new THREE.Sprite(
            new THREE.SpriteMaterial({ map: tex, depthTest: false }),
          );
          sp.position.copy(
            origin.clone().add(d.clone().multiplyScalar(arrowLen + 0.25)),
          );
          sp.scale.set(0.7, 0.26, 1);
          scene.add(sp);
        }
        const center = new THREE.Vector3(0, 0.55, 0);
        makeArrow(new THREE.Vector3(1, 0, 0), center, 0xff3b30, 'col 0  →');
        makeArrow(new THREE.Vector3(0, 1, 0), center, 0x34c759, 'col 1  ↑');
        makeArrow(new THREE.Vector3(0, 0, 1), center, 0x007aff, 'col 2  ↗');

        // Position dot (column 3)
        const posDot = new THREE.Mesh(
          new THREE.SphereGeometry(0.06, 16, 16),
          new THREE.MeshBasicMaterial({ color: 0xff9500 }),
        );
        posDot.position.copy(center);
        scene.add(posDot);
        // col 3 label
        const c3 = document.createElement('canvas');
        c3.width = 128;
        c3.height = 48;
        const ctx3 = c3.getContext('2d');
        ctx3.font = 'bold 28px Inter, sans-serif';
        ctx3.textAlign = 'center';
        ctx3.textBaseline = 'middle';
        ctx3.fillStyle = '#ff9500';
        ctx3.fillText('col 3  ●', 64, 24);
        const tex3 = new THREE.CanvasTexture(c3);
        const sp3 = new THREE.Sprite(
          new THREE.SpriteMaterial({ map: tex3, depthTest: false }),
        );
        sp3.position.set(0.55, 0.18, 0);
        sp3.scale.set(0.7, 0.26, 1);
        scene.add(sp3);

        let visible = false;
        const vObs = new IntersectionObserver(
          ([e]) => {
            visible = e.isIntersecting;
          },
          { threshold: 0.1 },
        );
        vObs.observe(canvas);
        (function tick() {
          requestAnimationFrame(tick);
          if (!visible) return;
          controls.update();
          renderer.render(scene, cam);
        })();
      }
      initMatrixViz('scene-matrix');

      /* ── Plane outline visualisation ── */
      function initOutlinesViz(canvasId) {
        const canvas = document.getElementById(canvasId);
        if (!canvas) return;
        const renderer = new THREE.WebGLRenderer({
          canvas,
          antialias: true,
          alpha: true,
        });
        renderer.setPixelRatio(Math.min(window.devicePixelRatio, 2));
        renderer.setSize(canvas.width, canvas.height, false);
        renderer.setClearColor(0xfafafa, 1);

        const scene = new THREE.Scene();
        const cam = new THREE.PerspectiveCamera(
          35,
          canvas.width / canvas.height,
          0.1,
          50,
        );
        cam.position.set(3.0, 2.6, 3.2);
        cam.lookAt(0, 0, 0);

        const controls = new OrbitControls(cam, canvas);
        controls.enableDamping = true;
        controls.dampingFactor = 0.08;
        controls.enableZoom = false;
        controls.enablePan = false;
        controls.autoRotate = true;
        controls.autoRotateSpeed = 1.0;

        // Subtle grid
        scene.add(new THREE.GridHelper(6, 12, 0xe0e0e0, 0xf0f0f0));

        // Helper: create a filled plane with a white outline border
        function makePlane(vertices, y, fillColor, fillOpacity) {
          const group = new THREE.Group();

          // Filled surface (translucent)
          const shape = new THREE.Shape();
          shape.moveTo(vertices[0][0], vertices[0][1]);
          for (let i = 1; i < vertices.length; i++) {
            shape.lineTo(vertices[i][0], vertices[i][1]);
          }
          shape.closePath();
          const fillGeo = new THREE.ShapeGeometry(shape);
          const fillMat = new THREE.MeshBasicMaterial({
            color: fillColor,
            transparent: true,
            opacity: fillOpacity,
            side: THREE.DoubleSide,
            depthWrite: false,
          });
          const fillMesh = new THREE.Mesh(fillGeo, fillMat);
          fillMesh.rotation.x = -Math.PI / 2;
          fillMesh.position.y = y;
          group.add(fillMesh);

          // White outline border (quad strip like the Swift code)
          const lineWidth = 0.015;
          const outlineGeo = new THREE.BufferGeometry();
          const positions = [];
          const n = vertices.length;
          for (let i = 0; i < n; i++) {
            const ax = vertices[i][0],
              az = vertices[i][1];
            const bx = vertices[(i + 1) % n][0],
              bz = vertices[(i + 1) % n][1];
            // Edge direction
            const dx = bx - ax,
              dz = bz - az;
            const len = Math.sqrt(dx * dx + dz * dz);
            if (len < 0.001) continue;
            // Perpendicular in XZ
            const px = (-dz / len) * lineWidth,
              pz = (dx / len) * lineWidth;
            const oy = y + 0.002; // sit slightly above surface
            // Two triangles forming a quad
            positions.push(
              ax - px,
              oy,
              az - pz,
              ax + px,
              oy,
              az + pz,
              bx + px,
              oy,
              bz + pz,
              ax - px,
              oy,
              az - pz,
              bx + px,
              oy,
              bz + pz,
              bx - px,
              oy,
              bz - pz,
            );
          }
          outlineGeo.setAttribute(
            'position',
            new THREE.Float32BufferAttribute(positions, 3),
          );
          const outlineMat = new THREE.MeshBasicMaterial({
            color: 0xffffff,
            transparent: true,
            opacity: 0.85,
            side: THREE.DoubleSide,
            depthWrite: false,
          });
          const outlineMesh = new THREE.Mesh(outlineGeo, outlineMat);
          group.add(outlineMesh);

          return group;
        }

        // Floor plane — large irregular quad
        const floor = makePlane(
          [
            [-1.3, -0.9],
            [1.4, -1.0],
            [1.5, 1.1],
            [-1.2, 1.2],
          ],
          0.0,
          0x0066ff,
          0.06,
        );
        scene.add(floor);

        // Table surface — elevated rectangle
        const table = makePlane(
          [
            [-0.4, -0.3],
            [0.4, -0.3],
            [0.4, 0.3],
            [-0.4, 0.3],
          ],
          0.7,
          0xea580c,
          0.08,
        );
        table.position.set(0.5, 0, -0.2);
        scene.add(table);

        // Shelf / step — another elevated plane
        const shelf = makePlane(
          [
            [-0.55, -0.2],
            [0.55, -0.2],
            [0.5, 0.25],
            [-0.5, 0.25],
          ],
          0.35,
          0x7c3aed,
          0.08,
        );
        shelf.position.set(-0.8, 0, 0.6);
        scene.add(shelf);

        // Table legs (thin boxes to give depth)
        const legMat = new THREE.MeshBasicMaterial({
          color: 0xcccccc,
          transparent: true,
          opacity: 0.25,
        });
        const legGeo = new THREE.BoxGeometry(0.03, 0.7, 0.03);
        [
          [-0.35, -0.25],
          [0.35, -0.25],
          [0.35, 0.25],
          [-0.35, 0.25],
        ].forEach(([lx, lz]) => {
          const leg = new THREE.Mesh(legGeo, legMat);
          leg.position.set(0.5 + lx, 0.35, -0.2 + lz);
          scene.add(leg);
        });

        // Shelf legs
        const slegGeo = new THREE.BoxGeometry(0.03, 0.35, 0.03);
        [
          [-0.5, -0.18],
          [0.5, -0.18],
          [0.45, 0.22],
          [-0.45, 0.22],
        ].forEach(([lx, lz]) => {
          const leg = new THREE.Mesh(slegGeo, legMat);
          leg.position.set(-0.8 + lx, 0.175, 0.6 + lz);
          scene.add(leg);
        });

        // Labels
        function makeLabel(text, pos, color) {
          const c2 = document.createElement('canvas');
          c2.width = 200;
          c2.height = 48;
          const ctx = c2.getContext('2d');
          ctx.font = 'bold 22px Inter, sans-serif';
          ctx.textAlign = 'center';
          ctx.textBaseline = 'middle';
          ctx.fillStyle = color;
          ctx.fillText(text, 100, 24);
          const tex = new THREE.CanvasTexture(c2);
          const sp = new THREE.Sprite(
            new THREE.SpriteMaterial({ map: tex, depthTest: false }),
          );
          sp.position.copy(pos);
          sp.scale.set(0.9, 0.22, 1);
          scene.add(sp);
        }
        makeLabel('floor plane', new THREE.Vector3(0, 0.18, 0), '#0066ff');
        makeLabel(
          'table surface',
          new THREE.Vector3(0.5, 0.92, -0.2),
          '#ea580c',
        );
        makeLabel('shelf', new THREE.Vector3(-0.8, 0.58, 0.6), '#7c3aed');

        let visible = false;
        const vObs = new IntersectionObserver(
          ([e]) => {
            visible = e.isIntersecting;
          },
          { threshold: 0.1 },
        );
        vObs.observe(canvas);
        (function tick() {
          requestAnimationFrame(tick);
          if (!visible) return;
          controls.update();
          renderer.render(scene, cam);
        })();
      }
      initOutlinesViz('scene-outlines');
    </script>
  </body>
</html>
